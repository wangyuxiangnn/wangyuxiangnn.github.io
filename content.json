[{"title":"windows 像 linux 一样执行命令","text":"安装 git 客户端 启动 Git Bash 然后就可以执行 linux 命令 1. 登陆 linux 服务器方法一: ssh kyle@ip &lt;回车&gt; 输入密码 方法二: 编辑用户目录下文件 vi ~/.ssh/config &lt;回车&gt; 执行命令: ssh kyle &lt;回车&gt; 输入密码 2. 传输文件到此服务器:scp 上传文件的路径 kyle:有权限的目标路径 &lt;回车&gt; 输入密码 3. idea 配置终端Tools/Terminal Shell path D:\\AppData\\Git\\bin\\bash.exe 然后打开idea里的Terminal 就可以执行 linux 命令","path":"/2019/3/24/","date":"03-24","preview":"https://images.pexels.com/photos/1563356/pexels-photo-1563356.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"“Never judge anyone shortly because every saint has a past and every sinner has a future. -Oscar Wilde <br/> 不要草率地评判一个人，因为每个圣人都有过去，每个罪人都有未来。 -奥斯卡﹒王尔德”"},{"title":"Centos7 基础命令","text":"查看某端口占用情况 netstatus: -a: 会列出所有连接 -t: 列出 TCP 协议的连接 -u: 列出 UDP 协议的连接 -n: 禁用域名解析功能 -l: 列出正在监听的套接字 -p: 查看进程信息 -r: 打印内核路由信息 -i: 打印网络接口信息 -ie: 输出用户友好的信息 CentOS 7 下 ss 替代 netstat原因: 在有大量 sockets 时，ss 更加高效快速。 ss -lntp|grep 8761 Linux 创建文件夹mkdir -p 1/2/3 根据程序名查看进程 ps aux|grep ps -ef|grep kyle:app $ ss -lntp|grep 8761 LISTEN 0 128 :::8761 :::* users:((&quot;java&quot;,pid=17565,fd=32)) kyle:app $ ps 17565 PID TTY STAT TIME COMMAND 17565 pts/0 SNl 0:46 java -jar pigx-eureka.jar vim 字符串全部替换1: 替换每一行中所有 vivian 为 sky :%s/vivian/sky/g(等同于 :g/vivian/s//sky/g)","path":"/2019/2/16/","date":"02-16","preview":"https://images.pexels.com/photos/719609/pexels-photo-719609.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"“I learned that courage was not the absence of fear, but the triumph over it. -Nelson Mandela <br/> 我明白了勇气不是没有恐惧，而是战胜恐惧。 -纳尔逊﹒曼德拉”"},{"title":"搭了一天的服务,终于可以用了","text":"搭建脚本1. wget --no-check-certificate https://raw.githubusercontent.com/teddysun/across/master/l2tp.sh chmod +x l2tp.sh sudo ./l2tp.sh 2. wget https://git.io/vpnsetup -O vpnsetup.sh 重启服务ubuntu@ip-172-31-29-17:~$ sudo systemctl restart ipsec.service ubuntu@ip-172-31-29-17:~$ sudo service xl2tpd restart ubuntu@ip-172-31-29-17:~$ ubuntu@ip-172-31-29-17:~$ sudo systemctl status ipsec.service 查看 udp 端口监听状态 [ubuntu@ip-172-31-29-17:~$ netstat -nupl (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name udp 0 0 127.0.0.1:4500 0.0.0.0:* - udp 0 0 172.31.29.17:4500 0.0.0.0:* - udp 0 0 0.0.0.0:4500 0.0.0.0:* - udp 0 0 127.0.0.1:500 0.0.0.0:* - udp 0 0 172.31.29.17:500 0.0.0.0:* - udp 0 0 0.0.0.0:500 0.0.0.0:* - udp 0 0 0.0.0.0:68 0.0.0.0:* - udp 0 0 0.0.0.0:1701 0.0.0.0:* - udp6 0 0 :::4500 :::* - udp6 0 0 ::1:500 :::* - udp6 0 0 :::500 :::* - # 查看连接日志 [ubuntu@ip-172-31-29-17:~$ tail -f /var/log/syslog Dec 8 10:09:39 ip-172-31-29-17 pppd[3436]: pppd 2.4.7 started by root, uid 0 Dec 8 10:09:39 ip-172-31-29-17 pppd[3436]: Using interface ppp0 Dec 8 10:09:39 ip-172-31-29-17 pppd[3436]: Connect: ppp0 &lt;--&gt; /dev/pts/1 Dec 8 10:09:43 ip-172-31-29-17 charon: 09[KNL] 192.168.42.1 appeared on ppp0 Dec 8 10:09:43 ip-172-31-29-17 charon: 02[KNL] 192.168.42.1 disappeared from ppp0 Dec 8 10:09:43 ip-172-31-29-17 charon: 15[KNL] 192.168.42.1 appeared on ppp0 Dec 8 10:09:43 ip-172-31-29-17 charon: 16[KNL] interface ppp0 activated Dec 8 10:09:43 ip-172-31-29-17 pppd[3436]: Cannot determine ethernet address for proxy ARP Dec 8 10:09:43 ip-172-31-29-17 pppd[3436]: local IP address 192.168.42.1 Dec 8 10:09:43 ip-172-31-29-17 pppd[3436]: remote IP address 192.168.42.10 Dec 8 10:09:56 ip-172-31-29-17 pppd[3436]: LCP terminated by peer (User request) Dec 8 10:09:56 ip-172-31-29-17 pppd[3436]: Connect time 0.3 minutes. Dec 8 10:09:56 ip-172-31-29-17 pppd[3436]: Sent 276380 bytes, received 59270 bytes.","path":"/2018/12/8/","date":"12-08","preview":null,"subtitle":"<p>Don't argue with the people of strong determination<br/> because they may change the fact. —Shakespeare</p><p>别和意志坚定的人争辩<br/>因为他们可以改变事实！—莎士比亚</p>"},{"title":"虚拟机Linux CentOS 桥接模式和NAT模式配置静态IP的完美方案","text":"配置静态IP实际上就是设置虚拟机的网络配置和linux的3个配置文件 桥接模式1、首先设置这台linux的网络适配器为桥接模式： 2、查看主机网络配置Ctrl + R 打开运行，输入cmd回车，然后输入ipconfig回车：记住IPv4地址和默认网关 3、虚拟机打开第一个配置文件：[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0 最后的eth0是网卡名字不是固定的。打开后按照如下修改： DEVICE=eth0 BOOTPROTO=static #静态IP的关键 HWADDR=00:0C:29:17:01:FC ONBOOT=yes 启动时加载 TYPE=Ethernet IPADDR=192.168.1.220 #自己设置静态IP，不冲突就可以 NETMASK=255.255.255.0 GATEWAY=192.168.1.1 #在主机配置中看到的默认网关 BROADCAST=192.168.1.255 DNS1=192.168.1.1 #设置和网关一样的值 DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no NM_CONTROLLED=yes 4、修改第二个配置文件：[root@localhost ~]# vim /etc/sysconfig/network 按照如下内容进行修改： NETWORKING=yes NETWORKING_IPV6=no #关掉IPv6 HOSTNAME=localhost.localdomain GATEWAY=192.168.1.1 #默认网关地址 5、修改第三个配置文件：[root@localhost ~]# vim /etc/resolv.conf 按以下内容修改： search localdomain nameserver 8.8.8.8 #DNS域名解析地址（首选） nameserver 192.168.1.1 #（备用）可以写成其它比如114.114.114.114 6、修改完毕之后重启网络服务：[root@localhost ~]# service network restart NAT模式1、同样，先设置虚拟机的网络适配器为NAT模式： 2、修改VMware的“虚拟网络编辑器”：点编辑 –&gt; 虚拟网络编辑器：打开之后首先点击NAT模式，然后去掉下面DHCP的勾，然后点击NAT设置：NAT默认设置了110网段，这个可以修改，修改的话要统一修改不要落下。没有特殊需求就不要修改了。打开NAT设置面板之后，记住下面红框中这个IP： 3、设置完成后，启动虚拟机，修改第一个配置文件，这次要按照NAT设置中的IP进行配置：[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0 按如下改动： DEVICE=eth0 BOOTPROTO=static HWADDR=00:0C:29:17:01:FC ONBOOT=yes TYPE=Ethernet IPADDR=192.168.110.128 #网段限制在110所以IP地址变了 NETMASK=255.255.255.0 GATEWAY=192.168.110.2 #按照NAT设置中的网关地址设置 BROADCAST=192.168.110.255 DNS1=192.168.110.2 DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no NM_CONTROLLED=yes 4、修改第二个配置文件：[root@localhost ~]# vim /etc/sysconfig/network 按如下改动： NETWORKING=yes NETWORKING_IPV6=no HOSTNAME=localhost.localdomain GATEWAY=192.168.110.2 5、修改第三个配置文件：[root@localhost ~]# vim /etc/resolv.conf 按如下改动： search localdomain nameserver 8.8.8.8 nameserver 192.168.110.2 6、修改完毕之后重启网络服务：[root@localhost ~]# service network restart 这是一个结尾","path":"/2018/12/5/","date":"12-05","preview":"https://images.pexels.com/photos/1645635/pexels-photo-1645635.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"<p>Don't argue with the people of strong determination<br/> because they may change the fact. —Shakespeare</p><p>别和意志坚定的人争辩<br/>因为他们可以改变事实！—莎士比亚</p>"},{"title":"Git 命令","text":"创建版本库$ git clone &lt;url&gt; #克隆远程版本库 $ git init #初始化本地版本库 修改和提交$ git status #查看状态 $ git diff #查看变更内容 $ git add . #跟踪所有改动过的文件 $ git add &lt;file&gt; #跟踪指定的文件 $ git mv &lt;old&gt;&lt;new&gt; #文件改名 $ git rm&lt;file&gt; #删除文件 $ git rm --cached&lt;file&gt; #停止跟踪文件但不删除 $ git commit -m &quot;commit messages&quot; #提交所有更新过的文件 $ git commit --amend #修改最后一次改动 查看提交历史$ git log #查看提交历史 $ git log -p &lt;file&gt; #查看指定文件的提交历史 $ git blame &lt;file&gt; #以列表方式查看指定文件的提交历史 撤销$ git reset --hard HEAD #撤销工作目录中所有未提交文件的修改内容 $ git checkout HEAD &lt;file&gt; #撤销指定的未提交文件的修改内容 $ git revert &lt;commit&gt; #撤销指定的提交 $ git log --before=&quot;1 days&quot; #退回到之前1天的版本 分支与标签$ git branch #显示所有本地分支 $ git checkout &lt;branch/tag&gt; #切换到指定分支和标签 $ git branch &lt;new-branch&gt; #创建新分支 $ git branch -d &lt;branch&gt; #删除本地分支 $ git tag #列出所有本地标签 $ git tag &lt;tagname&gt; #基于最新提交创建标签 $ git tag -d &lt;tagname&gt; #删除标签 合并与衍合$ git merge &lt;branch&gt; #合并指定分支到当前分支 $ git rebase &lt;branch&gt; #衍合指定分支到当前分支 远程操作$ git remote -v #查看远程版本库信息 $ git remote show &lt;remote&gt; #查看指定远程版本库信息 $ git remote add &lt;remote&gt; &lt;url&gt; #添加远程版本库 $ git fetch &lt;remote&gt; #从远程库获取代码 $ git pull &lt;remote&gt; &lt;branch&gt; #下载代码及快速合并 $ git push &lt;remote&gt; &lt;branch&gt; #上传代码及快速合并 $ git push &lt;remote&gt; :&lt;branch/tag-name&gt; #删除远程分支或标签 $ git push --tags #上传所有标签 success info(coding)➜ workspace git:(master) ✗ git pull fatal: No remote repository specified. Please, specify either a URL or a remote name from which new revisions should be fetched. ➜ workspace git:(master) ✗ git pull master master From git.dev.tencent.com:honghuhu/aurora * branch master -&gt; FETCH_HEAD Already up-to-date. ➜ workspace git:(master) ✗ git remote add origin git@git.dev.tencent.com:honghuhu/aurora.git ➜ workspace git:(master) ✗ git push fatal: The current branch master has no upstream branch. To push the current branch and set the remote as upstream, use git push --set-upstream origin master ➜ workspace git:(master) ✗ git push --set-upstream origin master Branch master set up to track remote branch master from origin. Everything up-to-date success info (本地)☁ aurora [master] git pull There is no tracking information for the current branch. Please specify which branch you want to merge with. See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt; If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=master/&lt;branch&gt; master ☁ aurora [master] git remote master ☁ aurora [master] git remote rm master ☁ aurora [master] git remote add origin git@git.dev.tencent.com:honghuhu/aurora.git ☁ aurora [master] git pull From git.dev.tencent.com:honghuhu/aurora * [new branch] master -&gt; origin/master There is no tracking information for the current branch. Please specify which branch you want to merge with. See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt; If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; master ☁ aurora [master] git push --set-upstream origin master Branch &#39;master&#39; set up to track remote branch &#39;master&#39; from &#39;origin&#39;. Everything up-to-date ☁ aurora [master] git pull Already up to date. ☁ aurora [master] git push Everything up-to-date","path":"/2018/11/30/","date":"11-30","preview":"https://images.pexels.com/photos/733767/pexels-photo-733767.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"<p>Love cures people-both the ones who give it and the ones who receive it.</p><p>爱会治愈人们,无论是那些给予它的人,还是那些得到它的人</p>"},{"title":"Spring中@Async注解","text":"项目中遇到了, Feign 调用微服务超时的问题,而调用的方法返回值为 void, 所以这种情况:如果非必要等待执行方法成功,则可以使用 spring 注解 @Async, 完美解决超时问题,从而程序可以正常执行 异步与同步的区别 同步就是整个处理过程顺序执行，当各个过程都执行完毕，并返回结果。 异步调用则是只是发送了调用的指令，调用者无需等待被调用的方法完全执行完毕；而是继续执行下面的流程。 @Async介绍 在Spring中，基于@Async标注的方法，称之为异步方法；这些方法将在执行的时候，将会在独立的线程中被执行，调用者无需等待它的完成，即可继续其他的操作。 基于Java配置的启用方式@Service @EnableAsync public class SyncServiceImpl {...} 代码中异步调用无返回值的使用方式@Service @EnableAsync public class SyncServiceImpl { @Async public void syncTest() { AtomicInteger page = new AtomicInteger(0); while (true) { if (page.page.get() == 50) { break; } logger.info(&quot;&lt;sync&gt; 第&quot; + page + &quot;页...&quot;); page.addAndGet(1); } logger.info(&quot;&lt;sync&gt; 异步结束&quot;); } }","path":"/2018/10/27/","date":"10-27","preview":"https://images.pexels.com/photos/7764/pexels-photo.jpg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"微服务间调用,处理一个用时比较久的任务<p style='color: #ff0000;font-size:25px;'>由于超时报错导致程序无法成功执行完成,怎么破?</p><p style='color: #f9690e;'>前提:被调用方法不需要返回结果</p>!"},{"title":"JSON格式化","text":"","path":"/2018/10/9/","date":"10-09","preview":"https://wx4.sinaimg.cn/large/00632Q2nly1fw21ew9ryaj31kw11yqv5.jpg","subtitle":"哇咔咔，成功了</br>这就是一个尚可的点子变成杰作的过程，因为没有哪个点子生来就完美。"},{"title":"MySql唯一键重复的处理","text":"向数据库插入记录时，有时会有这种需求，当符合某种条件的数据存在时，去修改它，不存在时，则新增，也就是saveOrUpdate操作。这种控制可以放在业务层，也可以放在数据库层，大多数数据库都支持这种需求，如Oracle的merge语句，再如本文所讲的MySQL中的INSERT … ON DUPLICATE KEY UPDATE语句。 该语句是基于唯一索引或主键使用，比如一个字段a被加上了unique index，并且表中已经存在了一条记录值为1，下面两个语句会有相同的效果： INSERT INTO tableName (a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE c=VALUES(c); UPDATE tableName SET c=3 WHERE a=1; ON DUPLICATE KEY UPDATE后面可以放多个字段，用英文逗号分割。使用ON DUPLICATE KEY UPDATE，最终如果插入了一个新行，则受影响的行数是1，如果修改了已存在的一行数据，则受影响的行数是2。 如果字段b也被加上了unique index，则该语句和下面的update语句是等效的: UPDATE tableName SET c=c+1 WHERE a=1 OR b=2 LIMIT 1; 如果a=1 OR b=2匹配了多行，则只有一行会被修改。通常的，在ON DUPLICATE KEY UPDATE语句中，我们应该避免多个唯一索引的情况。 如果需要插入或更新多条数据，并且更新的字段需要根据其它字段来运算时，可以使用如下语句： INSERT INTO tableName (a,b,c) VALUES (1,2,3),(4,5,6) ON DUPLICATE KEY UPDATE c=VALUES(a)+VALUES(b); 如果一个表中包含了一个auto_increment的字段，每次insert数据后，可以通过last_insert_id()方法返回最后自动生成的值，如果通过INSERT … ON DUPLICATE KEY UPDATE语句修改了一条数据，那么再通过last_insert_id()方法获取的值将不正确，实际测试中是多了一个数，比如向表中增加了3条数据，那么通过last_insert_id()方法得到的值是3，但是通过该语句修改了一条数据后，通过last_insert_id()方法得到的值是4。如果想解决该问题，可以通过如下语句： INSERT INTO tableName (a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE id=LAST_INSERT_ID(id), c=3; 如果是用主键primary或者唯一索引unique区分了记录的唯一性,避免重复插入记录可以使用： INSERT IGNORE INTO tableName (`email`, `phone`, `user_id`) VALUES (&#39;ttt.com&#39;, &#39;11&#39;, &#39;11111&#39;); mysql中primary key重复时的处理办法replace into tableName values (1 #主键或唯一索引#, &#39;newvalue&#39;); 这种情况下逻辑是这样的, mysql先判断记录是否存在, 若存在则先删除之, 再自行insert. 所以你能看到这条语句执行后affected rows是2条 insert into tableName values (1, &#39;xxx&#39;),(2,&#39;xxx&#39;) on duplicate key update name = VALUES(name); 这条语句的affected rows也是2.","path":"/2018/9/28/","date":"09-28","preview":"https://upload-images.jianshu.io/upload_images/12906348-fe76617065c58768.gif","subtitle":"a <span style='color: rgb(255, 0, 0);'>wicked</span> <span style='color: rgb(247, 150, 70);'>sense</span> of <span style='color: rgb(0, 176, 240);'>humour</span><br/><span style='color: rgb(255, 0, 0);'>顽皮的</span><span style='color: rgb(0, 176, 240);'>幽默</span><span style='color: rgb(247, 150, 70);'>感</span>"},{"title":"百度脑图- 便捷的思维工具","text":"将图片在新建标签页里打开一切经得起再度阅读的语言，一定值得再度思索——梭罗","path":"/2018/9/3/","date":"09-03","preview":"https://images.pexels.com/photos/1398655/pexels-photo-1398655.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"And that's how good ideas turn into great ideas, because no idea is born fully formed. </br>这就是一个尚可的点子变成杰作的过程，因为没有哪个点子生来就完美。"},{"title":"用Spring Cloud和Docker构建微服务","text":"摘要: 本文讲述了 Service Discovery、Externalized Configuration、API Gateway、Service Orchestration with Docker Compose 文章来源: dockone 什么是Spring Cloud?Spring Cloud 是Pivotal提供的用于简化分布式系统构建的工具集。Spring Cloud引入了云平台连接器(Cloud Connector)和服务连接器(Service Connector)的概念。云平台连接器是一个接口，需要由云平台提供者进行实现，以便库中的其他模块可以与该云平台协同工作。 Spring BootSpring Cloud最重要的一点是它可以和Spring Boot一起工作，Spring Boot可以帮助开发者更容易地创建基于Spring的应用程序和服务。 从Spring Boot项目名称中的Boot就可以看出来，Spring Boot的作用在于创建和启动新的基于Spring框架的项目。Spring Boot会选择最适合的Spring子项目和第三方开源库进行整合。大部分Spring Boot应用只需要非常少的配置就可以快速运行起来。Spring Boot包含的特性如下： 创建可以独立运行的Spring应用。 直接嵌入Tomcat或Jetty服务器，不需要部署WAR文件。 提供推荐的基础POM文件来简化Apache Maven配置。 尽可能的根据项目依赖来自动配置Spring框架。 提供可以直接在生产环境中使用的功能，如性能指标、应用信息和应用健康检查。 没有代码生成，也没有XML配置文件。 服务发现和智能路由 每一个服务都含有一个特定意义的微服务架构。当你在Spring Cloud上构建微服务架构时，这里有几个基本概念需要首先澄清下。首先，你需要要先创建Configuration Service和Discovery Service两个基础服务。如下图所示：上面的图片说明了四个微服务以及各个服务之间的依赖关系。 Configuration service处于最顶端，黄色标识，而且被其它微服务所依赖。 Discovery service处于最低端，蓝色标识，同时也被其它服务所依赖。 绿色标识的两个微服务是我们本系列博文中用到的两个应用案例：电影和观影建议。 Configuration ServiceConfiguration Service在微服务架构中是一个非常重要的组件。如12要素应用理论所说， 微服务应用的配置应该存储在环境中，而不是本地项目中。 Configuration service(配置服务)是一个必不可少的基础组件的原因是因为它可以对所有通过点对点和检索的基础服务进行服务管理。 假设我们有多个部署环境。比如我们有一个临时环境和一个生产环境，针对每个环境的配置将会是不同的。每一个configuration service 将会由一个独立的Git仓库来存放环境配置。没有其它环境能够访问到这个配置仓库，它只是提供该环境中运行的配置服务罢了。当Configuration service启动后，它将会指向那些根据配置文件配置的路径并启动对应服务。每一个微服务通过读取自己配置文件中的具体环境来运行。在这一过程中，配置是通过版本管理来进行的内部和集中化管理，更改配置不需要重启服务。 通过Spring Cloud提供的服务终端，你可以更改环境配置，并向Discovery service(发现服务)发送一个刷新信号，所有的用户都会收到新的配置通知。 Discovery ServiceDiscovery Service(发现服务)是另一个重要的微服务架构的组件。Discovery Service管理运行在容器中的众多服务实例，而这些实例工作在集群环境下。在这些应用中，我们使用客户端的方式称之为从服务到服务。举个例子，我使用Spring Cloud Feign ，这是一个基于Restful风格的微服务提供的客户端开源项目，它是从Netflix OSS project项目中派生出来的。 @FeignClient(&quot;movie&quot;) public interface MovieClient { @RequestMapping(method = RequestMethod.GET, value = &quot;/movies&quot;) PagedResources findAll(); @RequestMapping(method = RequestMethod.GET, value = &quot;/movies/{id}&quot;) Movie findById(@RequestParam(&quot;id&quot;) String id); @RequestMapping(method = RequestMethod.POST, value = &quot;/movies&quot;, produces = MediaType.APPLICATION_JSON_VALUE) void createMovie(@RequestBody Movie movie); } 在上面的例子中，我创建了一个Feign 客户端，并映射了一个REST API方法来暴露电影服务。使用@FeignClient注解，可以声明我想要为movie微服务而创建的客户端API。接下来我声明了一个我想要实现的服务映射。通过在方法上声明一个URL规则来描述一个REST API的路由规则。 更令人兴奋的是，这一切在Spring Cloud中都很容易，我所要做的仅仅是知道service ID来创建我的Feign 客户端。服务的URL地址在运行时环境是自动配置的，因为每一个在集群中的微服务将会在启动时通过绑定serviceid的方式来进行注册。 微服务架构中的其它服务，也是通过上面提到的方式运行。我只需要知道进行通讯服务的serviceid，所有的操作都是通过Spring自动绑定的。 API GatewayAPI Gateway 服务是Spring Cloud的另一个重要组件(关于它的介绍可以阅读本篇文章)。它可以用来管理集群服务中的领域实体。下图的绿色六边形是我们提供的数据驱动服务，主要用来管理自己的实体类和数据库。通过添加API Gateway服务，我们可以为通过下面绿颜色的服务为每一个API路由创建一个代理暴露接口。假设推荐服务和电影服务都暴露他们自己的REST API在自己管理的域实体上。API gataway通过discovery service和从其它服务注入的基于代理路由的 API方法。通过这种方式，包括推荐服务和电影服务将拥有一个完整定义的路由，通过暴露的REST API获得本地的微服务。API Gateway将会重定义路由请求到服务实例，这些请求都是基于HTTP的。 示例项目我已经在GitHub上创建了一个实例项目：https://github.com/kbastani/spring-cloud-microservice-example，这个项目是一个端到端的原生云平台，使用Spring Cloud构建实际的微服务架构。 基本概念: 使用Docker进行集成测试 混合持久化 微服务架构 服务发现 API网关 Docker 使用Docker对每一个服务进行构建和部署。使用Docker Compose在一个开发机上进行端到端的集成测试。 混合持久化混合持久化其实就是说使用多种数据库来存储。不同的微服务实例都会使用它们自己的数据库，并通过REST服务或者消息总线来通信，举个例子，你可以使用基于以下数据库来构建微服务： Neo4j(图形化)、MongoDB(文档化)、MySQL(关联) 微服务架构 这个例子演示了如何使用微服务创建一个新的应用。由于在项目中的每一个微服务只有一个单一的父项目。开发者为此得到的收益是可以在本机上运行和开发每一个微服务。添加一个新的微服务非常简单，当发现微服务时将会自动发现运行时的集群环境上。 Service Discovery项目中包含两个发现服务，一个在Netflix Eureka，另一个使用了 Consul from Hashicorp。多种发现服务提供了多种选择，一个是使用(Consul)来做DNS服务集群，另一个是(Consul)基于代理的API 网关。 API 网关每一个微服务都关联Eureka，在整个集群中检索API路由。使用这个策略，每一个在集群上运行的微服务只需要通过一个共同的API网关进行负载均衡和暴露接口，每一个服务也会自动发现并将路由请求转发到自己的路由服务中。这个代理技术有助于开发用户界面，作为平台完整的 API通过自己的主机映射为代理服务。 Docker 实例下面的实例将会通过Maven来构建，使用Docker为每一个微服务构建容器镜像。我们可以很优雅的使用Docker Compose在我们自己的主机上搭建全部的微服务集群。 开始构建 在这之前，请先移步至项目的GitHub 仓库。 https://github.com/kbastani/spring-cloud-microservice-example 克隆或者fork这个项目并且把源码下载到自己的电脑上。下载完毕后，你需要使用Maven和Docker来编译和构建本地的容器镜像。 下载Docker首先，如果你还没有Docker请先下载它，然后在开发机上安装并运行。 当然你也需要安装Docker Compose。 环境要求能够运行实例程序，需要在你的开发机上安装下面的软件： Maven 3、Java 8、Docker、Docker Compose 构建项目通过命令行方式来构建当前项目，在项目的根目录中运行如下的命令： $ mvn clean install 项目将会根据pom.xml中的每一个项目声明中下载相应的依赖jar包。每一个服务都将会被构建，同时Maven的Docker插件将会自动从本地Docker Registry中构建每一个容器镜像。Docker将会在构建成功后，根据命令行运行mvn clean install来清除相应的资源。 在项目成功构建后，你将会看到如下的输出： [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary: [INFO] [INFO] spring-cloud-microservice-example-parent 0.1.0-SNAPSHOT SUCCESS [ 0.707 s] [INFO] users-microservice 0.1.0 ........................... SUCCESS [ 15.891 s] [INFO] discovery-microservice 0.1.0 ....................... SUCCESS [ 6.863 s] [INFO] api-gateway-microservice 0.1.0 ..................... SUCCESS [ 4.520 s] [INFO] recommendation-microservice 0.1.0 .................. SUCCESS [ 6.988 s] [INFO] config-microservice 0.1.0 .......................... SUCCESS [ 6.203 s] [INFO] hystrix-dashboard 0.1.0 ............................ SUCCESS [ 4.467 s] [INFO] consul-microservice 0.1.0 .......................... SUCCESS [ 9.376 s] [INFO] movie-microservice 0.1.0 ........................... SUCCESS [ 7.799 s] [INFO] movies-ui 0.1.0 .................................... SUCCESS [ 35.211 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 01:40 min [INFO] Finished at: 2018-09-01T11:19:58+08:00 [INFO] ------------------------------------------------------------------------ 通过Docker compose 启动集群 现在每一个镜像都成功构建完毕，我们使用Docker Compose来加速启动我们的集群。我已经将Docker Compose的yaml文件包含进了项目中，大家可以从GitHub上获取。 现在我们通过下面的命令行启动微服务集群： $ docker-compose up 如果一切配置都是正确的，每一个容器镜像将会通过在Docker上的虚拟容器和自动发现的网络服务来运行。当他们开始顺序启动时，你将会看到一系列的日志输出。这可能需要一段时间来完成，取决于运行你实例程序的机器性能。 一旦容器启动成功，你将会通过Eureka主机看到通过Discovery service注册上来的应用服务。 通过命令行终端复制粘贴下面的命令到Docker中定义的$DOCKER_HOST环境变量中。 $ open $(echo \\&quot;$(echo $DOCKER_HOST)\\&quot;| \\sed &#39;s/tcp:\\/\\//http:\\/\\//g&#39;| \\sed &#39;s/[0-9]\\{4,\\}/8761/g&#39;| \\sed &#39;s/\\&quot;//g&#39;) 如果Eureka正确的启动，浏览器将会启动并打开Eureka服务的仪表盘，如下图所示：我们将会看到每一个正在运行的服务实例和状态。通过下面的命令来获取数据驱动服务，例如 movie 服务。 $ open $(echo \\&quot;$(echo $DOCKER_HOST)/movie\\&quot;| \\sed &#39;s/tcp:\\/\\//http:\\/\\//g&#39;| \\sed &#39;s/[0-9]\\{4,\\}/10000/g&#39;| \\sed &#39;s/\\&quot;//g&#39;) 这个命令将会访问根据导航网关终端提供的代理方式访问movie服务的REST API终端。这些REST API使用 HATEOAS 来配置，它是一个通过内嵌链接的方式支持自动发现服务的接口。 { &quot;_links&quot; : { &quot;self&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie&quot; }, &quot;resume&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/resume&quot; }, &quot;pause&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/pause&quot; }, &quot;restart&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/restart&quot; }, &quot;metrics&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/metrics&quot; }, &quot;env&quot; : [ { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/env&quot; }, { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/env&quot; } ], &quot;archaius&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/archaius&quot; }, &quot;beans&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/beans&quot; }, &quot;configprops&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/configprops&quot; }, &quot;trace&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/trace&quot; }, &quot;info&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/info&quot; }, &quot;health&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/health&quot; }, &quot;hystrix.stream&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/hystrix.stream&quot; }, &quot;routes&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/routes&quot; }, &quot;dump&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/dump&quot; }, &quot;refresh&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/refresh&quot; }, &quot;mappings&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/mappings&quot; }, &quot;autoconfig&quot; : { &quot;href&quot; : &quot;http://192.168.59.103:10000/movie/autoconfig&quot; } } } 总结 这是使用Spring Cloud和Docker构建微服务架构的系列博文的第一部分。在本文中，我们接触到了如下的概念: Service Discovery、Externalized Configuration、API Gateway、Service Orchestration with Docker Compose 项目来源 Github 环境版本&lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; 用Maven构建 DockerImage 遇到的问题 $ workspace mvn clean install ............. [INFO] spring-cloud-microservice-example-parent 0.1.0-SNAPSHOT SUCCESS [ 1.269 s] [INFO] users-microservice 0.1.0 ........................... FAILURE [ 32.674 s] [INFO] discovery-microservice 0.1.0 ....................... SKIPPED [INFO] api-gateway-microservice 0.1.0 ..................... SKIPPED [INFO] recommendation-microservice 0.1.0 .................. SKIPPED [INFO] config-microservice 0.1.0 .......................... SKIPPED [INFO] hystrix-dashboard 0.1.0 ............................ SKIPPED [INFO] consul-microservice 0.1.0 .......................... SKIPPED [INFO] movie-microservice 0.1.0 ........................... SKIPPED [INFO] movies-ui 0.1.0 .................................... SKIPPED [INFO] ------------------------------------------------------------------------ [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 51.569 s [INFO] Finished at: 2018-08-31T15:44:40+08:00 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal com.spotify:docker-maven-plugin:0.4.13:build (default) on project users-microservice: Exception caught: java.util.concurrent.ExecutionException: com.spotify.docker.client.shaded.javax.ws.rs.ProcessingException: java.io.IOException: No such file or directory -&gt; [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn &lt;goals&gt; -rf :users-microservice 解决方式 issues 修改环境变量 ➜ spring-cloud-microservice-example-master export DOCKER_HOST=unix:///var/run/docker.sock ➜ spring-cloud-microservice-example-master systemctl restart docker docker 删除无用镜像$ spring-cloud-microservice-example-master docker images REPOSITORY TAG IMAGE ID CREATED SIZE kbastani/movies-ui latest eb53c9a05123 7 minutes ago 761MB &lt;none&gt; &lt;none&gt; 3aebc8e7887a 18 hours ago 821MB elastic-job-lite-console latest b1251732b8bd 2 days ago 164MB waylau/docker-spring-boot latest e89293110aa1 2 days ago 177MB frolvlad/alpine-oraclejdk8 slim b9038ea51d02 2 weeks ago 163MB zookeeper latest eb85ac40e608 4 weeks ago 149MB hub.c.163.com/library/nginx latest 46102226f2fd 16 months ago 109MB hub.c.163.com/library/mysql latest 9e64176cd8a2 16 months ago 407MB java 8 d23bdf5b1b1b 19 months ago 643MB registry.cn-hangzhou.aliyuncs.com/chainone/centos7-jdk8-maven3.3.9 latest c9a2f484fae9 2 years ago 659MB gcr.io/google_containers/hyperkube v0.17.0 e7f1aac231de 3 years ago 198MB gcr.io/google_containers/etcd 2.0.9 d5d77b0a1030 3 years ago 12.8MB gcr.io/google_containers/pause 0.8.0 bf595365a558 3 years ago 242kB ➜ spring-cloud-microservice-example-master docker rmi 3aebc8e7887a Error response from daemon: conflict: unable to delete 3aebc8e7887a (must be forced) - image is being used by stopped container d568c78c0cd3 ➜ spring-cloud-microservice-example-master docker rm d568c78c0cd3 d568c78c0cd3 ➜ spring-cloud-microservice-example-master docker rmi 3aebc8e7887a Deleted: sha256:3aebc8e7887ae0eaf74e717b00af17018e4fd0c2c0588aaf7b6322fc5d46de99 Deleted: sha256:ea471022fcf6ba64ad2fd135be1eb81b2fbaa7e31eaed52186f0a0a64fa828b7 Deleted: sha256:0fdcd8ce40b64d9e8d4255b9a03a16d8ed8c56868ad06be9830b97e2d297e25a Deleted: sha256:b307b0942e2527049b6730f8ff625a840b343dfa5b2905a8f9c7b0d51666d8f7 Deleted: sha256:9e635bfc87c410e046e63fdc89e6e3b284bc47cb11bd16823dd66ff04e1c9362 Deleted: sha256:a45a2f540f96398da8415254078fde85ffc2e36f2c9abac1c64782664dc1fb5e","path":"/2018/9/1/","date":"09-01","preview":"https://wx4.sinaimg.cn/large/00632Q2nly1fw8q4omb7gj30yg0mynpd.jpg","subtitle":"网络让信息流动更快，信息也在网络里越来越会伪装，谁能说谁的网络和现实完全一样呢? 人和人之间就有一张网，你呈现出来的是你的伪装，你看到的是他人的假相。 所以才你忙我碌、你慌我张。 在焦虑里，更是在自以为解脱的得意里.....掩埋真相。 不固步自封，也不妄自菲薄，没人愿做他人的奴隶，那就做好自己的主人。"},{"title":"基于SpringDataJest的ES数据查询与统计","text":"命令查询职责分离模式(Command Query Responsibility Segregation，CQRS)从业务上分离修改 (Command，增，删，改，会对系统状态进行修改)和查询（Query，查，不会对系统状态进行修改)的行为。从而使得逻辑更加清晰，便于对不同部分进行针对性的优化。CQRS有以下几点有点： 分工明确，可以负责不同的部分； 将业务上的命令和查询的职责分离能够提高系统的性能、可扩展性和安全性。并且在系统的演化中能够保持高度的灵活性，能够防止出现CRUD模式中，对查询或者修改中的某一方进行改动，导致另一方出现问题的情况； 逻辑清晰，能够看到系统中的那些行为或者操作导致了系统的状态变化； 可以从数据驱动(Data-Driven) 转到任务驱动(Task-Driven)以及事件驱动(Event-Driven)。 因此Command使用普通数据库（关系型数据库或非关系型数据库），Query使用效率查询效率更高的Elasticsearch。 1. 项目构建 pom依赖如下: &lt;dependency&gt; &lt;groupId&gt;com.github.vanroy&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jest&lt;/artifactId&gt; &lt;version&gt;3.1.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.searchbox&lt;/groupId&gt; &lt;artifactId&gt;jest&lt;/artifactId&gt; &lt;version&gt;5.3.2&lt;/version&gt; &lt;/dependency&gt; 配置文件spring: data: jest: uri: http://127.0.0.1:9200 username: elastic password: elastic 2. 构造查询条件 package com.hfcsbc.esetl.domain; import lombok.Data; import org.springframework.data.elasticsearch.annotations.Document; import org.springframework.data.elasticsearch.annotations.Field; import org.springframework.data.elasticsearch.annotations.FieldType; import javax.persistence.Entity; import javax.persistence.Id; import javax.persistence.OneToOne; import java.util.Date; import java.util.List; /** * Create by zz on 2018/8/30 */ @Document(indexName = &quot;person_v1&quot;, type = &quot;personV1&quot;) public class Person { @Id private Long id; private String name; @Field(type = FieldType.Nested) private List&lt;Address&gt; address; private Integer number; private Integer status; private Date birthDay; @Field(type=FieldType.Long) private Date createTime; } package com.hfcsbc.esetl.domain; import lombok.Data; import javax.persistence.Entity; import javax.persistence.Id; /** * Create by zz on 2018/8/30 */ @Entity @Data public class Address { @Id private Long id; private String name; private Integer number; } 根据多个状态查询(类似于sql的in)BoolQueryBuilder queryBuidler = boolQuery() .should(termQuery(&quot;status&quot;, 1)) .should(termQuery(&quot;status&quot;, 2)) .should(termQuery(&quot;status&quot;, 3)) .should(termQuery(&quot;status&quot;, 4)) .should(termQuery(&quot;status&quot;, 5)); and链接查询(类似于sql的and)BoolQueryBuilder queryBuilder = boolQuery(); queryBuilder .must(queryBuilder1) .must(queryBuilder2) .must(queryBuilder3); range查询（类似于sql的between .. and ..)QueryBuilder rangeQuery1 = rangeQuery(&quot;birthDay&quot;).from(yesterday).to(today); //任何一种都可以 QueryBuilder rangeQuery2 = rangeQuery(&quot;createTime&quot;).lte(qaParam.getRangeEndTime()).gte(qaParam.getRangeStartTime()); 嵌套对象查询BoolQueryBuilder nested = boolQuery(); if (CollectionUtils.isNotEmpty(qaParam.getAddress())) { for (Address address : qaParam.getTags()) { nested.should(nestedQuery(&quot;address&quot;, termQuery(&quot;address.name.keyword&quot;, address.getName()), ScoreMode.None)); } } ScoreMode: 定义other join side中score是如何被使用的。如果不关注scoring，我们只需要设置成ScoreMode.None，此种方式会忽略评分因此会更高效和节约内存注: termQuery 中文条件查询,需在属性名后边添加 &lt; .keyword &gt; 3. 获取统计数据 非嵌套获取数据求和 SumAggregationBuilder sumBuilder = AggregationBuilders.sum(&quot;sum&quot;).field(&quot;number&quot;); SearchQuery searchQuery = new NativeSearchQueryBuilder() .withIndices(QUERY_INDEX) .withTypes(QUERY_TYPE) .withQuery(boolQueryBuilder) .addAggregation(sumBuilder).build(); AggregatedPage&lt;ParkingOrder&gt; account = (AggregatedPage&lt;ParkingOrder&gt;) esParkingOrderRepository.search(EsQueryBuilders.buildYesterdayArrearsSumQuery(employeeId)); int sum = account.getAggregation(&quot;sum&quot;, SumAggregation.class).getSum().intValue(); 嵌套数据求和SumAggregationBuilder sumBuilder = AggregationBuilders.sum(&quot;sum&quot;).field(&quot;adress.num&quot;); AggregationBuilder aggregationBuilder = AggregationBuilders.nested(&quot;nested&quot;, &quot;adress&quot;).subAggregation(sumBuilder); SearchQuery searchQuery = new NativeSearchQueryBuilder() .withIndices(QUERY_INDEX) .withTypes(QUERY_TYPE) .withQuery(boolQueryBuilder) .addAggregation((AbstractAggregationBuilder) aggregationBuilder).build(); AggregatedPage&lt;ParkingOrder&gt; account = (AggregatedPage&lt;ParkingOrder&gt;) esParkingOrderRepository.search(EsQueryBuilders.buildYesterdayArrearsSumQuery(employeeId)); int sum = account.getAggregation(&quot;nested&quot;, SumAggregation.class).getAggregation(&quot;sum&quot;, SumAggregation.class).getSum().intValue();","path":"/2018/8/30/","date":"08-30","preview":"https://images.pexels.com/photos/221361/pexels-photo-221361.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"用假的名字是因为要说真的故事 </br> Happy Birthday"},{"title":"用Docker构建、运行发布一个SpringBoot应用","text":"摘要: 本文演示了如何用 Docker 构建、运行、发布来一个 Spring Boot 应用。 Docker 简介 Docker 是一个 Linux 容器管理工具包，具备“社交”方面，允许用户发布容器的 image (镜像)，并使用别人发布的 image。 文章来源: 云栖社区 Docker简介 Docker 是一个 Linux 容器管理工具包，具备“社交”方面，允许用户发布容器的 image (镜像)，并使用别人发布的 image。Docker image 是用于运行容器化进程的方案，在本文中，我们将构建一个简单的 Spring Boot 应用程序。 环境配置 JDK 1.8+ 自行 百度 Maven 3.0+ 参考 博客园 Docker 最新版 有关 Docker 在的安装，自行 百度。 如果你的电脑不是 Linux 系统，最好装个虚拟机，在虚拟机里面装个 Linux ，因为 Docker 的依赖 Linux。 用 Maven 构建项目:创建目录结构（项目的目录结构因符合 Maven 的约定。） 在 *nix 系统下执行 mkdir -p src/main/java/docker_spring_boot ,生产如下结构 : └── src └── main └── java └── com └── waylau └── docker_spring_boot 创建 pom.xml 文件&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.waylau&lt;/groupId&gt; &lt;artifactId&gt;docker-spring-boot&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;docker-spring-boot&lt;/name&gt; &lt;description&gt;Getting started with Spring Boot and Docker&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- tag::plugin[] --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.3&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;${docker.image.prefix}/${project.artifactId}&lt;/imageName&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- end::plugin[] --&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;docker.image.prefix&gt;waylau&lt;/docker.image.prefix&gt; &lt;spring.boot.version&gt;1.3.3.RELEASE&lt;/spring.boot.version&gt; &lt;/properties&gt; &lt;/project&gt; Spring Boot Maven plugin&nbsp;提供了很多方便的功能：它收集的类路径上所有 jar 文件，并构建成一个单一的、可运行的“über-jar”，这使得它更方便地执行和传输服务。它搜索的&nbsp;public static void main()&nbsp;方法来标记为可运行的类。它提供了一个内置的依赖解析器，用于设置版本号以匹配&nbsp;Spring Boot 的依赖。您可以覆盖任何你想要的版本，但它会默认选择的 Boot 的版本集。Spotify 的&nbsp;docker-maven-plugin&nbsp;插件是用于构建 Maven 的 Docker ImageimageName指定了镜像的名字，本例为&nbsp;waylau/docker-spring-bootdockerDirectory指定 Dockerfile 的位置resources是指那些需要和 Dockerfile 放在一起，在构建镜像时使用的文件，一般应用 jar 包需要纳入。本例，只需一个 jar 文件。 编写 Spring Boot 应用src/main/java/com/waylau/docker_spring_boot/Application.java: package com.waylau.docker_spring_boot; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * 主应用入口 * @author &lt;a href=&quot;http://waylau.com&quot;&gt;waylau.com&lt;/a&gt; * @date 2016年3月19日 */ @SpringBootApplication @RestController public class Application { @RequestMapping(&quot;/&quot;) public String home() { return &quot;Hello Docker World.&quot; + &quot;&lt;br /&gt;Welcome to &lt;a href=&#39;http://waylau.com&#39;&gt;waylau.com&lt;/a&gt;&lt;/li&gt;&quot;; } public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 解释下上面的代码：类用&nbsp;@SpringBootApplication&nbsp;@RestController&nbsp;标识,可用 Spring MVC 来处理 Web 请求。@RequestMapping&nbsp;将&nbsp;/&nbsp;映射到&nbsp;home()&nbsp;，并将”Hello Docker World” 文本作为响应。main()&nbsp;方法使用 Spring Boot 的&nbsp;SpringApplication.run()&nbsp;方法来启动应用。 运行程序使用 Maven编译: mvn package 运行: java -jar target/docker-spring-boot-1.0.0.jar 访问项目 如果程序正确运行，浏览器访问 http://192.168.36.133:8080/，可以看到页面 “Hello Docker World.” 字样。 将项目容器化 Docker 使用 Dockerfile 文件格式来指定 image 层， 创建文件 src/main/docker/Dockerfile: FROM frolvlad/alpine-oraclejdk8:slim VOLUME /tmp ADD docker-spring-boot-1.0.0.jar app.jar ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] 解释下这个配置文件：VOLUME&nbsp;指定了临时文件目录为/tmp。其效果是在主机&nbsp;/var/lib/docker&nbsp;目录下创建了一个临时文件，并链接到容器的/tmp。改步骤是可选的，如果涉及到文件系统的应用就很有必要了。/tmp目录用来持久化到 Docker 数据文件夹，因为 Spring Boot 使用的内嵌 Tomcat 容器默认使用/tmp作为工作目录项目的 jar 文件作为 “app.jar” 添加到容器的ENTRYPOINT&nbsp;执行项目 app.jar。为了缩短&nbsp;Tomcat 启动时间，添加一个系统属性指向 “/dev/urandom” 作为 Entropy Source 构建 Docker Image执行构建成为 docker image: mvn package docker:build 运行运行 Docker Image docker run -p 8080:8080 -t waylau/docker-spring-boot [root@waylau spring-boot]# docker run -p 8080:8080 -t waylau/docker-spring-boot . ____ _ __ _ _ /\\\\ / ___&#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | &#39;_ | &#39;_| | &#39;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#39; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.3.3.RELEASE) 2016-03-20 08:45:51.276 INFO 1 --- [ main] c.waylau.docker_spring_boot.Application : Starting Application v1.0.0 on 048fb623038f with PID 1 (/app.jar started by root in /) 2016-03-20 08:45:51.289 INFO 1 --- [ main] c.waylau.docker_spring_boot.Application : No active profile set, falling back to default profiles: default 2016-03-20 08:45:51.722 INFO 1 --- [ main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@669af5fc: startup date [Sun Mar 20 08:45:51 GMT 2016]; root of context hierarchy 2016-03-20 08:45:54.874 INFO 1 --- [ main] o.s.b.f.s.DefaultListableBeanFactory : Overriding bean definition for bean &#39;beanNameViewResolver&#39; with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration; factoryMethodName=beanNameViewResolver; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/web/ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter; factoryMethodName=beanNameViewResolver; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [org/springframework/boot/autoconfigure/web/WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter.class]] 2016-03-20 08:45:57.893 INFO 1 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http) 2016-03-20 08:45:57.982 INFO 1 --- [ main] o.apache.catalina.core.StandardService : Starting service Tomcat 2016-03-20 08:45:57.984 INFO 1 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.0.32 2016-03-20 08:45:58.473 INFO 1 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2016-03-20 08:45:58.473 INFO 1 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 6877 ms 2016-03-20 08:45:59.672 INFO 1 --- [ost-startStop-1] o.s.b.c.e.ServletRegistrationBean : Mapping servlet: &#39;dispatcherServlet&#39; to [/] 2016-03-20 08:45:59.695 INFO 1 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: &#39;characterEncodingFilter&#39; to: [/*] 2016-03-20 08:45:59.701 INFO 1 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: &#39;hiddenHttpMethodFilter&#39; to: [/*] 2016-03-20 08:45:59.703 INFO 1 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: &#39;httpPutFormContentFilter&#39; to: [/*] 2016-03-20 08:45:59.703 INFO 1 --- [ost-startStop-1] o.s.b.c.embedded.FilterRegistrationBean : Mapping filter: &#39;requestContextFilter&#39; to: [/*] 2016-03-20 08:46:00.862 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@669af5fc: startup date [Sun Mar 20 08:45:51 GMT 2016]; root of context hierarchy 2016-03-20 08:46:01.166 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;{[/]}&quot; onto public java.lang.String com.waylau.docker_spring_boot.Application.home() 2016-03-20 08:46:01.189 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;{[/error],produces=[text/html]}&quot; onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) 2016-03-20 08:46:01.190 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;{[/error]}&quot; onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest) 2016-03-20 08:46:01.302 INFO 1 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2016-03-20 08:46:01.302 INFO 1 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2016-03-20 08:46:01.438 INFO 1 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2016-03-20 08:46:01.833 INFO 1 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup 2016-03-20 08:46:02.332 INFO 1 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http) 2016-03-20 08:46:02.343 INFO 1 --- [ main] c.waylau.docker_spring_boot.Application : Started Application in 13.194 seconds (JVM running for 15.828) 访问项目如果程序正确运行，浏览器访问 http://192.168.36.133:8080/，可以看到页面 “Hello Docker World.” 字样。 推送 image 到 Docker Hub首先，你在 Docker Hub 要有注册账号，且创建了相应的库； 其次，docker 推送前，先要登录，否则报unauthorized: access to the requested resource is not authorized的错误 执行： docker login 输出为： [root@waylau spring-boot]# docker login Username: waylau Password: Email: waylau521@gmail.com WARNING: login credentials saved in /root/.docker/config.json Login Succeeded 执行推送 docker push waylau/docker-spring-boot [root@waylau spring-boot]# docker push waylau/docker-spring-boot The push refers to a repository [docker.io/waylau/docker-spring-boot] 751d29eef02e: Layer already exists 4da3741f39c7: Pushed 5f70bf18a086: Layer already exists 7e4d0cb13643: Layer already exists 8f045733649f: Layer already exists latest: digest: sha256:eb4d5308ba1bb27489d808279e74784bda6761b3574f4298d746abba59b35164 size: 9415 镜像加速器Docker Hub 在国外，有时候拉取 Image 极其缓慢，可以使用国内的镜像来实现加速 阿里云 echo &quot;DOCKER_OPTS=\\&quot;--registry-mirror=https://yourlocation.mirror.aliyuncs.com\\&quot;&quot; | sudo tee -a /etc/default/docker sudo service docker restart 其中 https://yourlocation.mirror.aliyuncs.com 是您在阿里云注册后的专属加速器地址 DaoCloudsudo echo “DOCKER_OPTS=\\”\\$DOCKER_OPTS –registry-mirror=http://your-id.m.daocloud.io -d\\”” &gt;&gt; /etc/default/docker sudo service docker restart 其中 http://your-id.m.daocloud.io 是您在 DaoCloud 注册后的专属加速器地址 获取项目镜像，执行 docker pull waylau/docker-spring-boot","path":"/2018/8/29/","date":"08-29","preview":"https://images.pexels.com/photos/324030/pexels-photo-324030.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"基于知识的私有化过程的人生，是技术的人生，千篇一律，百无聊赖。基于智慧的人生，是艺术的人生，每一瞬间都是自由的，每一次呼吸都是个性化的。"},{"title":"SpringBoot 读取yaml文件","text":"九刀鱼基本类型的使用yml文件大部分使用的都是字符串，如果想使用其它类型，只要直接按其它类型写变量值就可以了。举例： #使用boolean my-switch: is-on: true Java中使用只要加上@Value就可以了： @Value(&quot;${my-switch.is-on}&quot;) private boolean switchOn; 使用其它类型也是一样的。 集合的使用举例： #使用int的list student: ids: [1, 2, 3, 4, 5] 或者： #使用int的list student: ids: - 1 - 2 - 3 - 4 - 5 这个时候要注意了，Java如果直接写成： @Value(&quot;${student.id}&quot;) private List&lt;Integer&gt; ids; 启动时会报错，Cannot resolve placeholder 什么的这时候应该新建一个对list属性的配置类： @Configuration @ConfigurationProperties(&quot;student&quot;) public class PropertyConfig{ private List&lt;Integer&gt; ids; // getter &amp; setter } 然后在要使用的地方自动注入，调用一个getter方法就可以得到配置文件中的值。 yml文件还可以存放对象和对象的集合，使用方法与基本类型类似。简单举例： #使用对象 student: id: 1 name: Bruce gender: male #使用对象集合 students: - id: 1 name: Bruce gender: male - id: 2 name: ... ...","path":"/2018/8/10/","date":"08-10","preview":"https://images.pexels.com/photos/1116302/pexels-photo-1116302.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"what squeaks and what doesn't, what to explore and what to ignore."},{"title":"Mybatis查询缓存引起的问题","text":"Mybatis在查询时会采用缓存机制，分为一级缓存和二级缓存，一级缓存默认就会开启，二级缓存需要配置才可以使用。 一级缓存基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该Session中的所有 Cache 就将清空。 二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache、Hazelcast等。 对于缓存数据更新机制，当某一个作用域(一级缓存Session/二级缓存Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将被clear。 在缓存的作用域中，如果调用的方法的参数一样，就会使用缓存中查询的结果，而不会再次查询数据库。 问题: ``` 此处为代码 public void updateXModel(XAbout xAbout){ XModel xModelAgo=xModelMapper.selectByPrimaryKey(xAbout.getXModelId()); if(xModelAgo != null &amp;&amp; !xModel.getPhone.equals(xAbout.getPhone)){ xModelAgo.setPhone(xAbout.getPhone); //问题做法 updatePhone(xModelAgo); // updatePhone(new XModel(xAbout.getXModelId(),xAbout.getPhone,null,null,null)); // 正确做法 } } public void updatePhone(XModel xModel){ XModel xModelAgo=xModelMapper.selectByPrimaryKey(xModel.getId()); if(xModelAgo != null &amp;&amp; xModelAgo.getPhone.equals(xModel.getPhone)){ //奇葩的是竟然相等。。。 } } ``` 定位问题:mybatis 在查询数据库，返回一个结果，当修改当前结果后，再次执行这个查询方法,返回的是修改后的结果。 在遇到比较复杂的业务逻辑的时候，比如需要迭代一个方法，获取一个树形结构的数据，此时由于方法会被多次调用，对数据库就会进行多次相同的查询，从第二次调用方法之后就会使用一级缓存。如果你在方法中对查询出来的结果对象直接进行了修改，比如修改了某个属性的值，在下一次调用方法是进行这个查询时，返回的结果是你修改过的结果对象，而不再是从数据库中查询出来的值了，这样可能就和预期的处理不同了，容易造成逻辑错误。因此，应该避免直接操作数据库查询获取的对象。 解决办法当作为参数传入另一个方法做逻辑处理，尽量避免直接操作数据库查询获取的对象; 应该 重新 new XModel(null,null,null,null,null) ok! 美图: 总结: 这样寡淡贫瘠的一生，遇到你却轰轰烈烈到不像自己。","path":"/2018/8/8/","date":"08-08","preview":"https://images.pexels.com/photos/1302940/pexels-photo-1302940.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"年少的承诺，执着的相守。看似美好，却是无情。"},{"title":"用户昵称允许设置 emoji 😄️","text":"utf8mb4兼容utf8，且比utf8能表示更多的字符。看unicode编码区，从1 ～ 126就属于传统utf8区，当然utf8mb4也兼容这个区，126行以下就是utf8mb4扩充区，什么时候你需要存储那些字符，你才用utf8mb4,否则只是浪费空间。 问题: 用户修改名称时，输入了表情，后台报错 ### Error updating database. Cause: java.sql.SQLException: Incorrect string value: &#39;\\xF0\\x9F\\x99\\x83\\xF0\\x9F...&#39; for column &#39;title&#39; at row 1 ### The error may involve com.insertSelective-Inline ### The error occurred while setting parameters ### SQL: insert into qww ( id, uid, title ) values ( ?, ?, ? ) ### Cause: java.sql.SQLException: Incorrect string value: &#39;\\xF0\\x9F\\x99\\x83\\xF0\\x9F...&#39; for column &#39;title&#39; at row 1 ; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: &#39;\\xF0\\x9F\\x99\\x83\\xF0\\x9F...&#39; for column &#39;title&#39; at row 1; nested exception is java.sql.SQLException: Incorrect string value: &#39;\\xF0\\x9F\\x99\\x83\\xF0\\x9F...&#39; for column &#39;title&#39; at row 1 定位问题:Emoji表情符号为4个字节的字符，而 utf8 字符集只支持1-3个字节的字符，导致无法写入数据库。注: MySQL的版本不能太低，低于5.5.3的版本不支持utf8mb4编码。 解决办法如果数据库默认编码为 utf8mb4，则不需要修改mysql表字符集，例如CREATE TABLE `my_table` ( `id` int(11) NOT NULL AUTO_INCREMENT, `create_time` datetime DEFAULT CURRENT_TIMESTAMP, `update_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `is_delete` tinyint(4) DEFAULT &#39;0&#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COMMENT=&#39;备注&#39;; 如果数据库默认编码不是utf8mb4 则需要修改MySQL数据库字符集# 修改数据库: ALTER DATABASE database_name CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci; # 修改表: ALTER TABLE table_name CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; # 修改表字段: ALTER TABLE table_name CHANGE column_name column_name VARCHAR(191) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; java 配置druid数据库链接池@Bean(name = &quot;dataSource&quot;) @Primary public DataSource dataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(driverClass); dataSource.setUrl(url); dataSource.setUsername(user); dataSource.setPassword(password); dataSource.setConnectionInitSqls(Arrays.asList(&quot;set names utf8mb4&quot;)); #须加入此行,获取mysql连接时，指定编码为utf8mb4 //configuration dataSource.setInitialSize(initialSize); dataSource.setMinIdle(minIdle); dataSource.setMaxActive(100); dataSource.setMaxWait(maxWait); dataSource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); dataSource.setValidationQuery(validationQuery); dataSource.setTestWhileIdle(testWhileIdle); dataSource.setTestOnBorrow(testOnBorrow); return dataSource; } 总结: hahas","path":"/2018/8/6/","date":"08-06","preview":"https://images.pexels.com/photos/379964/pexels-photo-379964.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"我要开花，是为了完成作为一株花的庄严生命，不管你们怎么看我，我都要开花！——林清玄《百合花开》"},{"title":"jvm排查问题心得","text":"jvm排查问题心得 source: java葵花宝典问题: 线程执行一个任务迟迟没有返回，应用假死。 接口响应缓慢，甚至请求超时。 CPU 高负载运行。 这类问题并不像一个空指针、数组越界这样明显好查，这时就需要刚才提到的内存模型、对象创建、线程等相关知识结合在一起来排查问题了。正好这次借助之前的一次生产问题来聊聊如何排查和解决问题。 我这其实是一个定时任务，在固定的时间会开启 N 个线程并发的从 Redis 中获取数据进行运算。 业务逻辑非常简单，但应用一般涉及到多线程之后再简单的事情都要小心对待。 现象: 原本只需要执行几分钟的任务执行了几个小时都没退出。翻遍了所有的日志都没找到异常。定位问题:最常见的工具就是 JDK 自带的那一套。 这次我使用了 jstack 来查看线程的执行情况，它的作用其实就是 dump 当前的线程堆栈。 当然在 dump 之前是需要知道我应用的 pid 的，可以使用 jps -v 这样的方式列出所有的 Java 进程。 或者直接使用 ps aux|grep java 拿到 pid=1523 了之后就可以利用 jstack 1523 &gt; 1523.log 这样的方式将 dump 文件输出到日志文件中。 如果应用简单不复杂，线程这些也比较少其实可以直接打开查看。 但复杂的应用导出来的日志文件也比较大还是建议用专业的分析工具。 我这里的日志比较少直接打开就可以了。 因为我清楚知道应用中开启的线程名称，所以直接根据线程名就可以在日志中找到相关的堆栈： 所以通常建议大家线程名字给的有意义，在排查问题时很有必要。 其实其他几个线程都和这里的堆栈类似，很明显的看出都是在做 Redis 连接。 于是我登录 Redis 查看了当前的连接数，发现已经非常高了。 这样 Redis 的响应自然也就变慢了。 接着利用 jps -v 列出了当前所以在跑的 Java 进程，果不其然有好几个应用都在查询 Redis，而且都是并发连接，问题自然就找到了。 解决办法所以问题的主要原因是：大量的应用并发查询 Redis，导致 Redis 的性能降低。既然找到了问题，那如何解决呢？ 减少同时查询 Redis 的应用，分开时段降低 Redis 的压力。 将 Redis 复制几个集群，各个应用分开查询。但是这样会涉及到数据的同步等运维操作，或者由程序了进行同步也会增加复杂度。 目前我们选择的是第一个方案，效果很明显。 建议 尽量不要在线程中做大量耗时的网络操作，如查询数据库（可以的话在一开始就将数据从从 DB 中查出准备好）。 尽可能的减少多线程竞争锁。可以将数据分段，各个线程分别读取。 多利用 CAS+自旋 的方式更新数据，减少锁的使用。 应用中加上 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp 参数，在内存溢出时至少可以拿到内存日志。 线程池监控。如线程池大小、队列大小、最大线程数等数据，可提前做好预估。 JVM 监控，可以看到堆内存的涨幅趋势，GC 曲线等数据，也可以提前做好准备。","path":"/2018/8/2/","date":"08-02","preview":"https://upload-images.jianshu.io/upload_images/12906348-d61e95349bd83eaa.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"一次次的经历，一次次得体会 AND 骄傲是断了引线的风筝稍纵即逝。"},{"title":"用了一个月的mybatis总结","text":"这是标题hahahas mybatis 使用集合java : List&lt;Integer&gt; getArticleIdByTags(List&lt;ArticleTag&gt; articles); mapper : &lt;select id=&quot;getArticleIdByTags&quot; parameterType=&quot;java.util.List&quot; resultType=&quot;java.lang.Integer&quot;&gt; select article_id from ymeixin_article_tag where is_delete = 0 &lt;foreach collection=&quot;list&quot; item=&quot;articleTag&quot; open=&quot;AND&quot; separator=&quot;OR&quot; close=&quot;GROUP BY article_id HAVING COUNT(*) &gt;=&quot;&gt; tag_id = #{articleTag.tagId,jdbcType=INTEGER} AND type = #{articleTag.type,jdbcType=INTEGER} &lt;/foreach&gt; ${list.size} --传入集合的长度（找一好久没找到，还是一位大哥告诉的） &lt;/select&gt; 自定义resultMapmapper : &lt;resultMap id=&quot;ResultTag&quot; type=&quot;com.ymeixin.model.Tag&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot; javaType=&quot;java.lang.Integer&quot; jdbcType=&quot;INTEGER&quot;/&gt; &lt;result property=&quot;name&quot; column=&quot;part_name&quot; javaType=&quot;java.lang.String&quot; jdbcType=&quot;VARCHAR&quot;/&gt; &lt;result property=&quot;type&quot; column=&quot;type&quot; javaType=&quot;java.lang.Integer&quot; jdbcType=&quot;INTEGER&quot;/&gt; &lt;/resultMap&gt; &lt;select id=&quot;getPopularTags&quot; parameterType=&quot;java.util.List&quot; resultMap=&quot;ResultTag&quot;&gt; select id,part_name,2 type from ymeixin_body_tag &lt;where&gt; is_delete = 0 AND id in &lt;foreach collection=&quot;list&quot; index=&quot;index&quot; item=&quot;id&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #{id} &lt;/foreach&gt; &lt;/where&gt; &lt;/select&gt; mapper遍历list mapjava : Map&lt;String, Object&gt; hashMap = new HashMap&lt;&gt;(); hashMap.put(&quot;previousMonth&quot;, new Date((System.currentTimeMillis() - 30L * 24 * 60 * 60 * 1000))); hashMap.put(&quot;limit&quot;, NumberProfile.TAG_NUM); List&lt;QaTag&gt; tagIds = qaTagMapper.getPopularTags(hashMap); mapper : &lt;select id=&quot;getPopularTags&quot; parameterType=&quot;java.util.Map&quot; resultMap=&quot;BaseResultMap&quot;&gt; select &lt;include refid=&quot;Base_Column_List&quot;/&gt; from ymeixin_qa_tag where create_time &gt; #{previousMonth} AND is_delete = 0 group by tag_id,type order by count(*) DESC limit #{limit} &lt;/select&gt; //map中包含list，直接根据key 取值 &lt;select id=&quot;selectTagByIds&quot; parameterType=&quot;java.util.Map&quot; resultMap=&quot;ResultTag&quot;&gt; select id,`name` from ymeixin_med_equ where is_delete = 0 AND type=#{type} &lt;foreach collection=&quot;ids&quot; index=&quot;index&quot; item=&quot;id&quot; open=&quot;AND id in (&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #{id} &lt;/foreach&gt; &lt;/select&gt;","path":"/2018/5/18/","date":"05-18","preview":"https://upload-images.jianshu.io/upload_images/12906348-344252255077df44.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"希望自己的格局通过一次次的经历变得更强大，而不是去专注与某个人某件事。"},{"title":"springboot相关配置","text":"1、SpringBoot注解作用: @SpringBootApplication这个Spring Boot核心注解是由其它三个重要的注解组合，分别是：@SpringBootConfiguration: 是SpringBoot项目的配置注解，这也是一个组合注解包含 @Configuration @EnableAutoConfiguration: 注解用于启用自动配置，该注解会使Spring Boot根据项目中依赖的jar包自动配置项目的配置项。 @ComponentScan: 是组件扫描注解，不配置默认扫描@SpringBootApplication所在类的同级目录以及它的子目录(这很重要,后面很应用到这个特性)。当然你也可以自己指定要扫描的 包目录 例如: @ComponentScan(basePackages = &quot;com.lqr.dem&quot;) 2、取消部分自动配置: @SpringBootApplication(exclude={DataSourceAutoConfiguration.class,HibernateJpaAutoConfiguration.class}) 3、全局配置文件（application.yml）: yml文件在书写时，需要注意一个地方：冒号与值中间是存在空格的！ 1.自定义属性 yml配置文件: wis: hive content: &quot;${wis} ok&quot; java代码: @Value(&quot;${wis}&quot;) 4、Web编码: 1. RestController @RestController = @Controller + @ResponseBody 2. http组合注解 @GetMapping =&gt; @RequestMapping(value = &quot;/xxx&quot;,method = RequestMethod.GET) @PostMapping =&gt; @RequestMapping(value = &quot;/xxx&quot;,method = RequestMethod.POST) @PutMapping =&gt; @RequestMapping(value = &quot;/xxx&quot;,method = RequestMethod.PUT) @DeleteMapping =&gt; @RequestMapping(value = &quot;/xxx&quot;,method = RequestMethod.DELETE) 3. 数据校验 1）@Valid + BindingResult 例: /** * 添加一个女生 */ @PostMapping(value = &quot;/girls&quot;) public Result&lt;Girl&gt; girlAdd(@Valid Girl girl, BindingResult bindingResult) { if (bindingResult.hasErrors()) { return ResultUtils.error(-1, bindingResult.getFieldError().getDefaultMessage()); } return ResultUtils.success(girlRespository.save(girl)); } 2）设置校验规则 例: public class Girl { private Integer id; @NotBlank(message = &quot;这个字段必传&quot;) private String cupSize; @Min(value = 18, message = &quot;未成年少女禁止入内&quot;) private Integer age; @NotNull(message = &quot;金额必传&quot;) private Double money; }","path":"/2018/4/11/","date":"04-11","preview":"https://wx4.sinaimg.cn/large/00632Q2nly1fw6niuom1hj30vb0ku7kl.jpg","subtitle":"不知道该写什么，多百度，总会有发现"},{"title":"mybatis深入理解(一)之 (#与$) 区别以及 sql 预编译","text":"引用自 github地址mybatis 中使用 sqlMap 进行 sql 查询时，经常需要动态传递参数，例如我们需要根据用户的姓名来筛选用户时，sql 如下： select * from user where name = &quot;ruhua&quot;; 上述 sql 中，我们希望 name 后的参数 “ruhua” 是动态可变的，即不同的时刻根据不同的姓名来查询用户。在 sqlMap 的 xml 文件中使用如下的 sql 可以实现动态传递参数 name： select * from user where name = #{name}; 或者 select * from user where name = &#39;${name}&#39;; 对于上述这种查询情况来说，使用 #{ } 和 ${ } 的结果是相同的，但是在某些情况下，我们只能使用二者其一。 ‘#’ 与 ‘$’ 区别动态 SQL 是 mybatis 的强大特性之一，也是它优于其他 ORM 框架的一个重要原因。mybatis 在对 sql 语句进行预编译之前，会对 sql 进行动态解析，解析为一个 BoundSql 对象，也是在此处对动态 SQL 进行处理的。 在动态 SQL 解析阶段， #{ } 和 ${ } 会有不同的表现： #{ } 解析为一个 JDBC 预编译语句（prepared statement）的参数标记符。 例如，sqlMap 中如下的 sql 语句 select * from user where name = #{name}; 解析为： select * from user where name = ?; 一个 #{ } 被解析为一个参数占位符 ? 。 而， ${ } 仅仅为一个纯碎的 string 替换，在动态 SQL 解析阶段将会进行变量替换 例如，sqlMap 中如下的 sql select * from user where name = &#39;${name}&#39;; 当我们传递的参数为 “ruhua” 时，上述 sql 的解析为： select * from user where name = &quot;ruhua&quot;; 预编译之前的 SQL 语句已经不包含变量 name 了。 综上所得， ${ } 的变量的替换阶段是在动态 SQL 解析阶段，而 #{ }的变量的替换是在 DBMS 中。 用法 tips 能使用 #{ } 的地方就用 #{ } 首先这是为了性能考虑的，相同的预编译 sql 可以重复利用。 其次，${ } 在预编译之前已经被变量替换了，这会存在 sql 注入问题。例如，如下的 sql， select * from ${tableName} where name = #{name} 假如，我们的参数 tableName 为 user; delete user; –，那么 SQL 动态解析阶段之后，预编译之前的 sql 将变为 select * from user; delete user; -- where name = ?; – 之后的语句将作为注释，不起作用，因此本来的一条查询语句偷偷的包含了一个删除表数据的 SQL！ 表名作为变量时，必须使用 ${ } 这是因为，表名是字符串，使用 sql 占位符替换字符串时会带上单引号 ‘’，这会导致 sql 语法错误，例如： select * from #{tableName} where name = #{name}; 预编译之后的sql 变为： select * from ? where name = ?; 假设我们传入的参数为 tableName = “user” , name = “ruhua”，那么在占位符进行变量替换后，sql 语句变为 select * from &#39;user&#39; where name=&#39;ruhua&#39;; 上述 sql 语句是存在语法错误的，表名不能加单引号 ‘’（注意，反引号 是可以的）。 sql预编译定义 sql 预编译指的是数据库驱动在发送 sql 语句和参数给 DBMS 之前对 sql 语句进行编译，这样 DBMS 执行 sql 时，就不需要重新编译。 为什么需要预编译JDBC 中使用对象 PreparedStatement 来抽象预编译语句，使用预编译 预编译阶段可以优化 sql 的执行。预编译之后的 sql 多数情况下可以直接执行，DBMS 不需要再次编译，越复杂的sql，编译的复杂度将越大，预编译阶段可以合并多次操作为一个操作。 预编译语句对象可以重复利用。把一个 sql 预编译后产生的 PreparedStatement 对象缓存下来，下次对于同一个sql，可以直接使用这个缓存的 PreparedState 对象。 mybatis 默认情况下，将对所有的 sql 进行预编译。 mysql预编译源码解析mysql 的预编译源码在 com.mysql.jdbc.ConnectionImpl 类中，如下： public synchronized java.sql.PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency) throws SQLException { checkClosed(); // // FIXME: Create warnings if can&#39;t create results of the given // type or concurrency // PreparedStatement pStmt = null; boolean canServerPrepare = true; // 不同的数据库系统对sql进行语法转换 String nativeSql = getProcessEscapeCodesForPrepStmts() ? nativeSQL(sql): sql; // 判断是否可以进行服务器端预编译 if (this.useServerPreparedStmts &amp;&amp; getEmulateUnsupportedPstmts()) { canServerPrepare = canHandleAsServerPreparedStatement(nativeSql); } // 如果可以进行服务器端预编译 if (this.useServerPreparedStmts &amp;&amp; canServerPrepare) { // 是否缓存了PreparedStatement对象 if (this.getCachePreparedStatements()) { synchronized (this.serverSideStatementCache) { // 从缓存中获取缓存的PreparedStatement对象 pStmt = (com.mysql.jdbc.ServerPreparedStatement)this.serverSideStatementCache.remove(sql); if (pStmt != null) { // 缓存中存在对象时对原 sqlStatement 进行参数清空等 ((com.mysql.jdbc.ServerPreparedStatement)pStmt).setClosed(false); pStmt.clearParameters(); } if (pStmt == null) { try { // 如果缓存中不存在，则调用服务器端(数据库)进行预编译 pStmt = ServerPreparedStatement.getInstance(getLoadBalanceSafeProxy(), nativeSql, this.database, resultSetType, resultSetConcurrency); if (sql.length() &lt; getPreparedStatementCacheSqlLimit()) { ((com.mysql.jdbc.ServerPreparedStatement)pStmt).isCached = true; } // 设置返回类型以及并发类型 pStmt.setResultSetType(resultSetType); pStmt.setResultSetConcurrency(resultSetConcurrency); } catch (SQLException sqlEx) { // Punt, if necessary if (getEmulateUnsupportedPstmts()) { pStmt = (PreparedStatement) clientPrepareStatement(nativeSql, resultSetType, resultSetConcurrency, false); if (sql.length() &lt; getPreparedStatementCacheSqlLimit()) { this.serverSideStatementCheckCache.put(sql, Boolean.FALSE); } } else { throw sqlEx; } } } } } else { // 未启用缓存时，直接调用服务器端进行预编译 try { pStmt = ServerPreparedStatement.getInstance(getLoadBalanceSafeProxy(), nativeSql, this.database, resultSetType, resultSetConcurrency); pStmt.setResultSetType(resultSetType); pStmt.setResultSetConcurrency(resultSetConcurrency); } catch (SQLException sqlEx) { // Punt, if necessary if (getEmulateUnsupportedPstmts()) { pStmt = (PreparedStatement) clientPrepareStatement(nativeSql, resultSetType, resultSetConcurrency, false); } else { throw sqlEx; } } } } else { // 不支持服务器端预编译时调用客户端预编译（不需要数据库 connection ） pStmt = (PreparedStatement) clientPrepareStatement(nativeSql, resultSetType, resultSetConcurrency, false); } return pStmt; } 流程图如下所示： mybatis之sql动态解析以及预编译源码 mybatis sql 动态解析 mybatis 在调用 connection 进行 sql 预编译之前，会对sql语句进行动态解析，动态解析主要包含如下的功能： 占位符的处理 动态sql的处理 参数类型校验 mybatis强大的动态SQL功能的具体实现就在此。动态解析涉及的东西太多，以后再讨论。 总结： 本文主要深入探究了 mybatis 对 #{ } 和 ${ }的不同处理方式，并了解了 sql 预编译。","path":"/2018/4/9/","date":"04-09","preview":"https://upload-images.jianshu.io/upload_images/12906348-7bdfd2d357487060.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"喜欢一件事，就一定要坚持不懈得去完成他，elastic job 有时间去学习"},{"title":"JVM 垃圾回收器工作原理及使用实例介绍","text":"问题 Java的内存泄漏引用自 IBM垃圾收集基础Java 语言的一大特点就是可以进行自动垃圾回收处理，而无需开发人员过于关注系统资源，例如内存资源的释放情况。自动垃圾收集虽然大大减轻了开发人员的工作量，但是也增加了软件系统的负担。 拥有垃圾收集器可以说是 Java 语言与 C++语言的一项显著区别。在 C++语言中，程序员必须小心谨慎地处理每一项内存分配，且内存使用完后必须手工释放曾经占用的内存空间。当内存释放不够完全时，即存在分配但永不释放的内存块，就会引起内存泄漏，严重时甚至导致程序瘫痪。 以下列举了垃圾回收器常用的算法及实验原理： 引用计数法 (Reference Counting)引用计数器在微软的 COM 组件技术中、Adobe 的 ActionScript3 种都有使用。 引用计数器的实现很简单，对于一个对象 A，只要有任何一个对象引用了 A，则 A 的引用计数器就加 1，当引用失效时，引用计数器就减 1。只要对象 A 的引用计数器的值为 0，则对象 A 就不可能再被使用。 引用计数器的实现也非常简单，只需要为每个对象配置一个整形的计数器即可。但是引用计数器有一个严重的问题，即无法处理循环引用的情况。因此，在 Java 的垃圾回收器中没有使用这种算法。 一个简单的循环引用问题描述如下：有对象 A 和对象 B，对象 A 中含有对象 B 的引用，对象 B 中含有对象 A 的引用。此时，对象 A 和对象 B 的引用计数器都不为 0。但是在系统中却不存在任何第 3 个对象引用了 A 或 B。也就是说，A 和 B 是应该被回收的垃圾对象，但由于垃圾对象间相互引用，从而使垃圾回收器无法识别，引起内存泄漏。 标记-清除算法 (Mark-Sweep)标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。一种可行的实现是，在标记阶段首先通过根节点，标记所有从根节点开始的较大对象。因此，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。该算法最大的问题是存在大量的空间碎片，因为回收后的空间是不连续的。在对象的堆空间分配过程中，尤其是大对象的内存分配，不连续的内存空间的工作效率要低于连续的空间。 复制算法 (Copying)将现有的内存空间分为两快，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收。 如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大。因此在真正需要垃圾回收的时刻，复制算法的效率是很高的。又由于对象在垃圾回收过程中统一被复制到新的内存空间中，因此，可确保回收后的内存空间是没有碎片的。该算法的缺点是将系统内存折半。 Java 的新生代串行垃圾回收器中使用了复制算法的思想。新生代分为 eden 空间、from 空间、to 空间 3 个部分。其中 from 空间和 to 空间可以视为用于复制的两块大小相同、地位相等，且可进行角色互换的空间块。from 和 to 空间也称为 survivor 空间，即幸存者空间，用于存放未被回收的对象。 在垃圾回收时，eden 空间中的存活对象会被复制到未使用的 survivor 空间中 (假设是 to)，正在使用的 survivor 空间 (假设是 from) 中的年轻对象也会被复制到 to 空间中 (大对象，或者老年对象会直接进入老年带，如果 to 空间已满，则对象也会直接进入老年代)。此时，eden 空间和 from 空间中的剩余对象就是垃圾对象，可以直接清空，to 空间则存放此次回收后的存活对象。这种改进的复制算法既保证了空间的连续性，又避免了大量的内存空间浪费。 标记-压缩算法 (Mark-Compact)复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在年轻代经常发生，但是在老年代更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活的对象较多，复制的成本也将很高。 标记-压缩算法是一种老年代的回收算法，它在标记-清除算法的基础上做了一些优化。也首先需要从根节点开始对所有可达对象做一次标记，但之后，它并不简单地清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。这种方法既避免了碎片的产生，又不需要两块相同的内存空间，因此，其性价比比较高。 增量算法 (Incremental Collecting)在垃圾回收过程中，应用软件将处于一种 CPU 消耗很高的状态。在这种 CPU 消耗很高的状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。 增量算法的基本思想是，如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。 分代 (Generational Collecting)根据垃圾回收对象的特性，不同阶段最优的方式是使用合适的算法用于本阶段的垃圾回收，分代算法即是基于这种思想，它将内存区间根据对象的特点分成几块，根据每块内存区间的特点，使用不同的回收算法，以提高垃圾回收的效率。以 Hot Spot 虚拟机为例，它将所有的新建对象都放入称为年轻代的内存区域，年轻代的特点是对象会很快回收，因此，在年轻代就选择效率较高的复制算法。当一个对象经过几次回收后依然存活，对象就会被放入称为老生代的内存空间。在老生代中，几乎所有的对象都是经过几次垃圾回收后依然得以幸存的。因此，可以认为这些对象在一段时期内，甚至在应用程序的整个生命周期中，将是常驻内存的。如果依然使用复制算法回收老生代，将需要复制大量对象。再加上老生代的回收性价比也要低于新生代，因此这种做法也是不可取的。根据分代的思想，可以对老年代的回收使用与新生代不同的标记-压缩算法，以提高垃圾回收效率。 从不同角度分析垃圾收集器，可以将其分为不同的类型。 按线程数分，可以分为串行垃圾回收器和并行垃圾回收器。串行垃圾回收器一次只使用一个线程进行垃圾回收；并行垃圾回收器一次将开启多个线程同时进行垃圾回收。在并行能力较强的 CPU 上，使用并行垃圾回收器可以缩短 GC 的停顿时间。 按照工作模式分，可以分为并发式垃圾回收器和独占式垃圾回收器。并发式垃圾回收器与应用程序线程交替工作，以尽可能减少应用程序的停顿时间；独占式垃圾回收器 (Stop the world) 一旦运行，就停止应用程序中的其他所有线程，直到垃圾回收过程完全结束。 按碎片处理方式可分为压缩式垃圾回收器和非压缩式垃圾回收器。压缩式垃圾回收器会在回收完成后，对存活对象进行压缩整理，消除回收后的碎片；非压缩式的垃圾回收器不进行这步操作。 按工作的内存区间，又可分为新生代垃圾回收器和老年代垃圾回收器。 可以用以下指标评价一个垃圾处理器的好坏。 吞吐量：指在应用程序的生命周期内，应用程序所花费的时间和系统总运行时间的比值。系统总运行时间=应用程序耗时+GC 耗时。如果系统运行了 100min，GC 耗时 1min，那么系统的吞吐量就是 (100-1)/100=99%。 垃圾回收器负载：和吞吐量相反，垃圾回收器负载指来记回收器耗时与系统运行总时间的比值。 停顿时间：指垃圾回收器正在运行时，应用程序的暂停时间。对于独占回收器而言，停顿时间可能会比较长。使用并发的回收器时，由于垃圾回收器和应用程序交替运行，程序的停顿时间会变短，但是，由于其效率很可能不如独占垃圾回收器，故系统的吞吐量可能会较低。 垃圾回收频率：指垃圾回收器多长时间会运行一次。一般来说，对于固定的应用而言，垃圾回收器的频率应该是越低越好。通常增大堆空间可以有效降低垃圾回收发生的频率，但是可能会增加回收产生的停顿时间。 反应时间：指当一个对象被称为垃圾后多长时间内，它所占据的内存空间会被释放。 堆分配：不同的垃圾回收器对堆内存的分配方式可能是不同的。一个良好的垃圾收集器应该有一个合理的堆内存区间划分。 JVM 垃圾回收器分类 新生代串行收集器串行收集器主要有两个特点：第一，它仅仅使用单线程进行垃圾回收；第二，它独占式的垃圾回收。 在串行收集器进行垃圾回收时，Java 应用程序中的线程都需要暂停，等待垃圾回收的完成，这样给用户体验造成较差效果。虽然如此，串行收集器却是一个成熟、经过长时间生产环境考验的极为高效的收集器。新生代串行处理器使用复制算法，实现相对简单，逻辑处理特别高效，且没有线程切换的开销。在诸如单 CPU 处理器或者较小的应用内存等硬件平台不是特别优越的场合，它的性能表现可以超过并行回收器和并发回收器。在 HotSpot 虚拟机中，使用-XX：+UseSerialGC 参数可以指定使用新生代串行收集器和老年代串行收集器。当 JVM 在 Client 模式下运行时，它是默认的垃圾收集器。一次新生代串行收集器的工作输出日志类似如清单 1 信息 (使用-XX:+PrintGCDetails 开关) 所示。 清单 1. 一次新生代串行收集器的工作输出日志 [GC [DefNew: 3468K-&gt;150K(9216K), 0.0028638 secs][Tenured: 1562K-&gt;1712K(10240K), 0.0084220 secs] 3468K-&gt;1712K(19456K), [Perm : 377K-&gt;377K(12288K)], 0.0113816 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 它显示了一次垃圾回收前的新生代的内存占用量和垃圾回收后的新生代内存占用量，以及垃圾回收所消耗的时间。 老年代串行收集器老年代串行收集器使用的是标记-压缩算法。和新生代串行收集器一样，它也是一个串行的、独占式的垃圾回收器。由于老年代垃圾回收通常会使用比新生代垃圾回收更长的时间，因此，在堆空间较大的应用程序中，一旦老年代串行收集器启动，应用程序很可能会因此停顿几秒甚至更长时间。虽然如此，老年代串行回收器可以和多种新生代回收器配合使用，同时它也可以作为 CMS 回收器的备用回收器。若要启用老年代串行回收器，可以尝试使用以下参数：-XX:+UseSerialGC: 新生代、老年代都使用串行回收器。 清单 2. 一次老年代串行收集器的工作输出日志 Heap def new generation total 4928K, used 1373K [0x27010000, 0x27560000, 0x2c560000) eden space 4416K, 31% used [0x27010000, 0x27167628, 0x27460000) from space 512K, 0% used [0x27460000, 0x27460000, 0x274e0000) to space 512K, 0% used [0x274e0000, 0x274e0000, 0x27560000) tenured generation total 10944K, used 0K [0x2c560000, 0x2d010000, 0x37010000) the space 10944K, 0% used [0x2c560000, 0x2c560000, 0x2c560200, 0x2d010000) compacting perm gen total 12288K, used 376K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706e0b8, 0x3706e200, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 如果使用-XX:+UseParNewGC 参数设置，表示新生代使用并行收集器，老年代使用串行收集器，如清单 3 所示。 清单 3. 一次串并行收集器混合使用的工作输出日志 Heap par new generation total 4928K, used 1373K [0x0f010000, 0x0f560000, 0x14560000) eden space 4416K, 31% used [0x0f010000, 0x0f167620, 0x0f460000) from space 512K, 0% used [0x0f460000, 0x0f460000, 0x0f4e0000) to space 512K, 0% used [0x0f4e0000, 0x0f4e0000, 0x0f560000) tenured generation total 10944K, used 0K [0x14560000, 0x15010000, 0x1f010000) the space 10944K, 0% used [0x14560000, 0x14560000, 0x14560200, 0x15010000) compacting perm gen total 12288K, used 2056K [0x1f010000, 0x1fc10000, 0x23010000) the space 12288K, 16% used [0x1f010000, 0x1f2121d0, 0x1f212200, 0x1fc10000) No shared spaces configured. 如果使用-XX:+UseParallelGC 参数设置，表示新生代和老年代均使用并行回收收集器。如清单 4 所示。 清单 4. 一次老年代并行回收器的工作输出日志 [Full GC [Tenured: 1712K-&gt;1699K(10240K), 0.0071963 secs] 1712K-&gt;1699K(19456K), [Perm : 377K-&gt;372K(12288K)], 0.0072393 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 它显示了垃圾回收前老年代和永久区的内存占用量，以及垃圾回收后老年代和永久区的内存使用量。 并行收集器并行收集器是工作在新生代的垃圾收集器，它只简单地将串行回收器多线程化。它的回收策略、算法以及参数和串行回收器一样。 并行回收器也是独占式的回收器，在收集过程中，应用程序会全部暂停。但由于并行回收器使用多线程进行垃圾回收，因此，在并发能力比较强的 CPU 上，它产生的停顿时间要短于串行回收器，而在单 CPU 或者并发能力较弱的系统中，并行回收器的效果不会比串行回收器好，由于多线程的压力，它的实际表现很可能比串行回收器差。 开启并行回收器可以使用参数-XX:+UseParNewGC，该参数设置新生代使用并行收集器，老年代使用串行收集器。 清单 5. 设置参数-XX:+UseParNewGC 的输出日志 [GC [ParNew: 825K-&gt;161K(4928K), 0.0155258 secs][Tenured: 8704K-&gt;661K(10944K), 0.0071964 secs] 9017K-&gt;661K(15872K), [Perm : 2049K-&gt;2049K(12288K)], 0.0228090 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] Heap par new generation total 4992K, used 179K [0x0f010000, 0x0f570000, 0x14560000) eden space 4480K, 4% used [0x0f010000, 0x0f03cda8, 0x0f470000) from space 512K, 0% used [0x0f470000, 0x0f470000, 0x0f4f0000) to space 512K, 0% used [0x0f4f0000, 0x0f4f0000, 0x0f570000) tenured generation total 10944K, used 8853K [0x14560000, 0x15010000, 0x1f010000) the space 10944K, 80% used [0x14560000, 0x14e057c0, 0x14e05800, 0x15010000) compacting perm gen total 12288K, used 2060K [0x1f010000, 0x1fc10000, 0x23010000) the space 12288K, 16% used [0x1f010000, 0x1f213228, 0x1f213400, 0x1fc10000) No shared spaces configured. 设置参数-XX:+UseConcMarkSweepGC 可以要求新生代使用并行收集器，老年代使用 CMS。 清单 6. 设置参数-XX:+UseConcMarkSweepGC 的输出日志 [GC [ParNew: 8967K-&gt;669K(14784K), 0.0040895 secs] 8967K-&gt;669K(63936K), 0.0043255 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap par new generation total 14784K, used 9389K [0x03f50000, 0x04f50000, 0x04f50000) eden space 13184K, 66% used [0x03f50000, 0x047d3e58, 0x04c30000) from space 1600K, 41% used [0x04dc0000, 0x04e67738, 0x04f50000) to space 1600K, 0% used [0x04c30000, 0x04c30000, 0x04dc0000) concurrent mark-sweep generation total 49152K, used 0K [0x04f50000, 0x07f50000, 0x09f50000) concurrent-mark-sweep perm gen total 12288K, used 2060K [0x09f50000, 0x0ab50000, 0x0df50000) 并行收集器工作时的线程数量可以使用-XX:ParallelGCThreads 参数指定。一般，最好与 CPU 数量相当，避免过多的线程数影响垃圾收集性能。在默认情况下，当 CPU 数量小于 8 个，ParallelGCThreads 的值等于 CPU 数量，大于 8 个，ParallelGCThreads 的值等于 3+[5*CPU_Count]/8]。以下测试显示了笔者笔记本上运行 8 个线程时耗时最短，本人笔记本是 8 核 IntelCPU。 清单 7. 设置为 8 个线程后 GC 输出 [GC [ParNew: 8967K-&gt;676K(14784K), 0.0036983 secs] 8967K-&gt;676K(63936K), 0.0037662 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap par new generation total 14784K, used 9395K [0x040e0000, 0x050e0000, 0x050e0000) eden space 13184K, 66% used [0x040e0000, 0x04963e58, 0x04dc0000) from space 1600K, 42% used [0x04f50000, 0x04ff9100, 0x050e0000) to space 1600K, 0% used [0x04dc0000, 0x04dc0000, 0x04f50000) concurrent mark-sweep generation total 49152K, used 0K [0x050e0000, 0x080e0000, 0x0a0e0000) concurrent-mark-sweep perm gen total 12288K, used 2060K [0x0a0e0000, 0x0ace0000, 0x0e0e0000) 清单 8. 设置为 128 个线程后 GC 输出 [GC [ParNew: 8967K-&gt;664K(14784K), 0.0207327 secs] 8967K-&gt;664K(63936K), 0.0208077 secs] [Times: user=0.03 sys=0.00, real=0.02 secs]清单 9. 设置为 640 个线程后 GC 输出 [GC [ParNew: 8967K-&gt;667K(14784K), 0.2323704 secs] 8967K-&gt;667K(63936K), 0.2324778 secs] [Times: user=0.34 sys=0.02, real=0.23 secs]清单 10. 设置为 1280 个线程后 GC 输出 Error occurred during initialization of VM Too small new size specified 新生代并行回收 (Parallel Scavenge) 收集器新生代并行回收收集器也是使用复制算法的收集器。从表面上看，它和并行收集器一样都是多线程、独占式的收集器。但是，并行回收收集器有一个重要的特点：它非常关注系统的吞吐量。 新生代并行回收收集器可以使用以下参数启用： -XX:+UseParallelGC:新生代使用并行回收收集器，老年代使用串行收集器。 -XX:+UseParallelOldGC:新生代和老年代都是用并行回收收集器。 清单 11. 设置为 24 个线程后 GC 输出 Heap PSYoungGen total 4800K, used 893K [0x1dac0000, 0x1e010000, 0x23010000) eden space 4160K, 21% used [0x1dac0000,0x1db9f570,0x1ded0000) from space 640K, 0% used [0x1df70000,0x1df70000,0x1e010000) to space 640K, 0% used [0x1ded0000,0x1ded0000,0x1df70000) ParOldGen total 19200K, used 16384K [0x13010000, 0x142d0000, 0x1dac0000) object space 19200K, 85% used [0x13010000,0x14010020,0x142d0000) PSPermGen total 12288K, used 2054K [0x0f010000, 0x0fc10000, 0x13010000) object space 12288K, 16% used [0x0f010000,0x0f2119c0,0x0fc10000) 新生代并行回收收集器可以使用以下参数启用： -XX:+MaxGCPauseMills:设置最大垃圾收集停顿时间，它的值是一个大于 0 的整数。收集器在工作时会调整 Java 堆大小或者其他一些参数，尽可能地把停顿时间控制在 MaxGCPauseMills 以内。如果希望减少停顿时间，而把这个值设置得很小，为了达到预期的停顿时间，JVM 可能会使用一个较小的堆 (一个小堆比一个大堆回收快)，而这将导致垃圾回收变得很频繁，从而增加了垃圾回收总时间，降低了吞吐量。 -XX:+GCTimeRatio：设置吞吐量大小，它的值是一个 0-100 之间的整数。假设 GCTimeRatio 的值为 n，那么系统将花费不超过 1/(1+n) 的时间用于垃圾收集。比如 GCTimeRatio 等于 19，则系统用于垃圾收集的时间不超过 1/(1+19)=5%。默认情况下，它的取值是 99，即不超过 1%的时间用于垃圾收集。 除此之外，并行回收收集器与并行收集器另一个不同之处在于，它支持一种自适应的 GC 调节策略，使用-XX:+UseAdaptiveSizePolicy 可以打开自适应 GC 策略。在这种模式下，新生代的大小、eden 和 survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。在手工调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量 (GCTimeRatio) 和停顿时间 (MaxGCPauseMills)，让虚拟机自己完成调优工作。 清单 12. 新生代并行回收收集器 GC 输出 Heap PSYoungGen total 4800K, used 893K [0x1dac0000, 0x1e010000, 0x23010000) eden space 4160K, 21% used [0x1dac0000,0x1db9f570,0x1ded0000) from space 640K, 0% used [0x1df70000,0x1df70000,0x1e010000) to space 640K, 0% used [0x1ded0000,0x1ded0000,0x1df70000) PSOldGen total 19200K, used 16384K [0x13010000, 0x142d0000, 0x1dac0000) object space 19200K, 85% used [0x13010000,0x14010020,0x142d0000) PSPermGen total 12288K, used 2054K [0x0f010000, 0x0fc10000, 0x13010000) object space 12288K, 16% used [0x0f010000,0x0f2119c0,0x0fc10000) 它也显示了收集器的工作成果，也就是回收前的内存大小和回收后的内存大小，以及花费的时间。 老年代并行回收收集器老年代的并行回收收集器也是一种多线程并发的收集器。和新生代并行回收收集器一样，它也是一种关注吞吐量的收集器。老年代并行回收收集器使用标记-压缩算法，JDK1.6 之后开始启用。 使用-XX:+UseParallelOldGC 可以在新生代和老生代都使用并行回收收集器，这是一对非常关注吞吐量的垃圾收集器组合，在对吞吐量敏感的系统中，可以考虑使用。参数-XX:ParallelGCThreads 也可以用于设置垃圾回收时的线程数量。 清单 13 是设置线程数量为 100 时老年代并行回收收集器输出日志： 清单 13. 老年代并行回收收集器设置 100 线程时 GC 输出 Heap PSYoungGen total 4800K, used 893K [0x1dac0000, 0x1e010000, 0x23010000) eden space 4160K, 21% used [0x1dac0000,0x1db9f570,0x1ded0000) from space 640K, 0% used [0x1df70000,0x1df70000,0x1e010000) to space 640K, 0% used [0x1ded0000,0x1ded0000,0x1df70000) ParOldGen total 19200K, used 16384K [0x13010000, 0x142d0000, 0x1dac0000) object space 19200K, 85% used [0x13010000,0x14010020,0x142d0000) PSPermGen total 12288K, used 2054K [0x0f010000, 0x0fc10000, 0x13010000) object space 12288K, 16% used [0x0f010000,0x0f2119c0,0x0fc10000) CMS 收集器与并行回收收集器不同，CMS 收集器主要关注于系统停顿时间。CMS 是 Concurrent Mark Sweep 的缩写，意为并发标记清除，从名称上可以得知，它使用的是标记-清除算法，同时它又是一个使用多线程并发回收的垃圾收集器。 CMS 工作时，主要步骤有：初始标记、并发标记、重新标记、并发清除和并发重置。其中初始标记和重新标记是独占系统资源的，而并发标记、并发清除和并发重置是可以和用户线程一起执行的。因此，从整体上来说，CMS 收集不是独占式的，它可以在应用程序运行过程中进行垃圾回收。 根据标记-清除算法，初始标记、并发标记和重新标记都是为了标记出需要回收的对象。并发清理则是在标记完成后，正式回收垃圾对象；并发重置是指在垃圾回收完成后，重新初始化 CMS 数据结构和数据，为下一次垃圾回收做好准备。并发标记、并发清理和并发重置都是可以和应用程序线程一起执行的。 CMS 收集器在其主要的工作阶段虽然没有暴力地彻底暂停应用程序线程，但是由于它和应用程序线程并发执行，相互抢占 CPU，所以在 CMS 执行期内对应用程序吞吐量造成一定影响。CMS 默认启动的线程数是 (ParallelGCThreads+3)/4),ParallelGCThreads 是新生代并行收集器的线程数，也可以通过-XX:ParallelCMSThreads 参数手工设定 CMS 的线程数量。当 CPU 资源比较紧张时，受到 CMS 收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。 由于 CMS 收集器不是独占式的回收器，在 CMS 回收过程中，应用程序仍然在不停地工作。在应用程序工作过程中，又会不断地产生垃圾。这些新生成的垃圾在当前 CMS 回收过程中是无法清除的。同时，因为应用程序没有中断，所以在 CMS 回收过程中，还应该确保应用程序有足够的内存可用。因此，CMS 收集器不会等待堆内存饱和时才进行垃圾回收，而是当前堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在 CMS 工作过程中依然有足够的空间支持应用程序运行。 这个回收阈值可以使用-XX:CMSInitiatingOccupancyFraction 来指定，默认是 68。即当老年代的空间使用率达到 68%时，会执行一次 CMS 回收。如果应用程序的内存使用率增长很快，在 CMS 的执行过程中，已经出现了内存不足的情况，此时，CMS 回收将会失败，JVM 将启动老年代串行收集器进行垃圾回收。如果这样，应用程序将完全中断，直到垃圾收集完成，这时，应用程序的停顿时间可能很长。因此，根据应用程序的特点，可以对-XX:CMSInitiatingOccupancyFraction 进行调优。如果内存增长缓慢，则可以设置一个稍大的值，大的阈值可以有效降低 CMS 的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。反之，如果应用程序内存使用率增长很快，则应该降低这个阈值，以避免频繁触发老年代串行收集器。 标记-清除算法将会造成大量内存碎片，离散的可用空间无法分配较大的对象。在这种情况下，即使堆内存仍然有较大的剩余空间，也可能会被迫进行一次垃圾回收，以换取一块可用的连续内存，这种现象对系统性能是相当不利的，为了解决这个问题，CMS 收集器还提供了几个用于内存压缩整理的算法。 -XX:+UseCMSCompactAtFullCollection 参数可以使 CMS 在垃圾收集完成后，进行一次内存碎片整理。内存碎片的整理并不是并发进行的。-XX:CMSFullGCsBeforeCompaction 参数可以用于设定进行多少次 CMS 回收后，进行一次内存压缩。 -XX:CMSInitiatingOccupancyFraction 设置为 100，同时设置-XX:+UseCMSCompactAtFullCollection 和-XX:CMSFullGCsBeforeCompaction，日志输出如下： 清单 14.CMS 垃圾回收器 GC 输出 [GC [DefNew: 825K-&gt;149K(4928K), 0.0023384 secs][Tenured: 8704K-&gt;661K(10944K), 0.0587725 secs] 9017K-&gt;661K(15872K), [Perm : 374K-&gt;374K(12288K)], 0.0612037 secs] [Times: user=0.01 sys=0.02, real=0.06 secs] Heap def new generation total 4992K, used 179K [0x27010000, 0x27570000, 0x2c560000) eden space 4480K, 4% used [0x27010000, 0x2703cda8, 0x27470000) from space 512K, 0% used [0x27470000, 0x27470000, 0x274f0000) to space 512K, 0% used [0x274f0000, 0x274f0000, 0x27570000) tenured generation total 10944K, used 8853K [0x2c560000, 0x2d010000, 0x37010000) the space 10944K, 80% used [0x2c560000, 0x2ce057c8, 0x2ce05800, 0x2d010000) compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706db10, 0x3706dc00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) G1 收集器 (Garbage First)G1 收集器的目标是作为一款服务器的垃圾收集器，因此，它在吞吐量和停顿控制上，预期要优于 CMS 收集器。 与 CMS 收集器相比，G1 收集器是基于标记-压缩算法的。因此，它不会产生空间碎片，也没有必要在收集完成后，进行一次独占式的碎片整理工作。G1 收集器还可以进行非常精确的停顿控制。它可以让开发人员指定当停顿时长为 M 时，垃圾回收时间不超过 N。使用参数-XX:+UnlockExperimentalVMOptions –XX:+UseG1GC 来启用 G1 回收器，设置 G1 回收器的目标停顿时间：-XX:MaxGCPauseMills=20,-XX:GCPauseIntervalMills=200。 收集器对系统性能的影响通过清单 15 所示代码运行 1 万次循环，每次分配 512*100B 空间，采用不同的垃圾回收器，输出程序运行所消耗的时间。 清单 15. 性能测试代码 import java.util.HashMap; public class GCTimeTest { static HashMap map = new HashMap(); public static void main(String[] args) { long begintime = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) { if (map.size() * 512 / 1024 / 1024 &gt;= 400) { map.clear();//保护内存不溢出 System.out.println(&quot;clean map&quot;); } byte[] b1; for (int j = 0; j &lt; 100; j++) { b1 = new byte[512]; map.put(System.nanoTime(), b1);//不断消耗内存 } } long endtime = System.currentTimeMillis(); System.out.println(endtime - begintime); } } 使用参数-Xmx512M -Xms512M -XX:+UseParNewGC 运行代码，输出如下： clean map 8565 cost time=1655 使用参数-Xmx512M -Xms512M -XX:+UseParallelOldGC –XX:ParallelGCThreads=8 运行代码，输出如下： clean map 8798 cost time=1998 使用参数-Xmx512M -Xms512M -XX:+UseSerialGC 运行代码，输出如下： clean map 8864 cost time=1717 使用参数-Xmx512M -Xms512M -XX:+UseConcMarkSweepGC 运行代码，输出如下： clean map 8862 cost time=1530 上面例子的 GC 输出可以看出，采用不同的垃圾回收机制及设定不同的线程数，对于代码段的整体执行时间有较大的影响。需要读者有针对性地选用适合自己代码段的垃圾回收机制。 GC 相关参数总结 与串行回收器相关的参数 -XX:+UseSerialGC:在新生代和老年代使用串行回收器。 -XX:+SurvivorRatio:设置 eden 区大小和 survivor 区大小的比例。 -XX:+PretenureSizeThreshold:设置大对象直接进入老年代的阈值。当对象的大小超过这个值时，将直接在老年代分配。 -XX:MaxTenuringThreshold:设置对象进入老年代的年龄的最大值。每一次 Minor GC 后，对象年龄就加 1。任何大于这个年龄的对象，一定会进入老年代。 与并行 GC 相关的参数 -XX:+UseParNewGC: 在新生代使用并行收集器。 -XX:+UseParallelOldGC: 老年代使用并行回收收集器。 -XX:ParallelGCThreads：设置用于垃圾回收的线程数。通常情况下可以和 CPU 数量相等。但在 CPU 数量比较多的情况下，设置相对较小的数值也是合理的。 -XX:MaxGCPauseMills：设置最大垃圾收集停顿时间。它的值是一个大于 0 的整数。收集器在工作时，会调整 Java 堆大小或者其他一些参数，尽可能地把停顿时间控制在 MaxGCPauseMills 以内。 -XX:GCTimeRatio:设置吞吐量大小，它的值是一个 0-100 之间的整数。假设 GCTimeRatio 的值为 n，那么系统将花费不超过 1/(1+n) 的时间用于垃圾收集。 -XX:+UseAdaptiveSizePolicy:打开自适应 GC 策略。在这种模式下，新生代的大小，eden 和 survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。 与 CMS 回收器相关的参数 -XX:+UseConcMarkSweepGC: 新生代使用并行收集器，老年代使用 CMS+串行收集器。 -XX:+ParallelCMSThreads: 设定 CMS 的线程数量。 -XX:+CMSInitiatingOccupancyFraction:设置 CMS 收集器在老年代空间被使用多少后触发，默认为 68%。 -XX:+UseFullGCsBeforeCompaction:设定进行多少次 CMS 垃圾回收后，进行一次内存压缩。 -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收。 -XX:+CMSParallelRemarkEndable:启用并行重标记。 -XX:CMSInitatingPermOccupancyFraction:当永久区占用率达到这一百分比后，启动 CMS 回收 (前提是-XX:+CMSClassUnloadingEnabled 激活了)。 -XX:UseCMSInitatingOccupancyOnly:表示只在到达阈值的时候，才进行 CMS 回收。 -XX:+CMSIncrementalMode:使用增量模式，比较适合单 CPU。 与 G1 回收器相关的参数 -XX:+UseG1GC：使用 G1 回收器。 -XX:+UnlockExperimentalVMOptions:允许使用实验性参数。 -XX:+MaxGCPauseMills:设置最大垃圾收集停顿时间。 -XX:+GCPauseIntervalMills:设置停顿间隔时间。 其他参数 -XX:+DisableExplicitGC: 禁用显示 GC。 结束语通过本文的学习，读者可以掌握基本的 JVM 垃圾回收器设计原理及使用规范。基于笔者多年的工作经验，没有哪一条优化是可以照本宣科的，它一定是基于您对 JVM 垃圾回收器工作原理及自身程序设计有一定了解前提下，通过大量的实验来找出最适合自己的优化方案。","path":"/2018/4/8/","date":"04-08","preview":"https://upload-images.jianshu.io/upload_images/12906348-5f2471d3cb923886.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"忙于采集的蜜蜂，无暇在人前高谈阔论。"},{"title":"JVM 优化经验总结","text":"引用自 IBM 开始之前Java 虚拟机有自己完善的硬件架构, 如处理器、堆栈、寄存器等，还具有相应的指令系统。JVM 屏蔽了与具体操作系统平台相关的信息，使得 Java 程序只需生成在 Java 虚拟机上运行的目标代码 (字节码), 就可以在多种平台上不加修改地运行。Java 虚拟机在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。 注意：本文仅针对 JDK7、HotSPOT Java 虚拟机，对于 JDK8 引入的 JVM 新特性及其他 Java 虚拟机，本文不予关注。 我们以一个例子开始这篇文章。假设你是一个普通的 Java 对象，你出生在 Eden 区，在 Eden 区有许多和你差不多的小兄弟、小姐妹，可以把 Eden 区当成幼儿园，在这个幼儿园里大家玩了很长时间。Eden 区不能无休止地放你们在里面，所以当年纪稍大，你就要被送到学校去上学，这里假设从小学到高中都称为 Survivor 区。开始的时候你在 Survivor 区里面划分出来的的“From”区，读到高年级了，就进了 Survivor 区的“To”区，中间由于学习成绩不稳定，还经常来回折腾。直到你 18 岁的时候，高中毕业了，该去社会上闯闯了。于是你就去了年老代，年老代里面人也很多。在年老代里，你生活了 20 年 (每次 GC 加一岁)，最后寿终正寝，被 GC 回收。有一点没有提，你在年老代遇到了一个同学，他的名字叫爱德华 (慕光之城里的帅哥吸血鬼)，他以及他的家族永远不会死，那么他们就生活在永生代。 之前的文章《JVM 垃圾回收器工作原理及使用实例介绍》中已经介绍过年轻代、年老代、永生代，本文主要讲讲如何运用这些区域，为系统性能提供更好的帮助。本文不再重复这些概念，直接进入主题。 如何将新对象预留在年轻代众所周知，由于 Full GC 的成本远远高于 Minor GC，因此某些情况下需要尽可能将对象分配在年轻代，这在很多情况下是一个明智的选择。虽然在大部分情况下，JVM 会尝试在 Eden 区分配对象，但是由于空间紧张等问题，很可能不得不将部分年轻对象提前向年老代压缩。因此，在 JVM 参数调优时可以为应用程序分配一个合理的年轻代空间，以最大限度避免新对象直接进入年老代的情况发生。清单 1 所示代码尝试分配 4MB 内存空间，观察一下它的内存使用情况。 清单 1. 相同大小内存分配 public class PutInEden { public static void main(String[] args){ byte[] b1,b2,b3,b4;//定义变量 b1=new byte[1024*1024];//分配 1MB 堆空间，考察堆空间的使用情况 b2=new byte[1024*1024]; b3=new byte[1024*1024]; b4=new byte[1024*1024]; } } 使用 JVM 参数-XX:+PrintGCDetails -Xmx20M -Xms20M 运行清单 1 所示代码，输出如清单 2 所示。 清单 2. 清单 1 运行输出 [GC [DefNew: 5504K-&gt;640K(6144K), 0.0114236 secs] 5504K-&gt;5352K(19840K), 0.0114595 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] [GC [DefNew: 6144K-&gt;640K(6144K), 0.0131261 secs] 10856K-&gt;10782K(19840K), 0.0131612 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] [GC [DefNew: 6144K-&gt;6144K(6144K), 0.0000170 secs][Tenured: 10142K-&gt;13695K(13696K), 0.1069249 secs] 16286K-&gt;15966K(19840K), [Perm : 376K-&gt;376K(12288K)], 0.1070058 secs] [Times: user=0.03 sys=0.00, real=0.11 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0302067 secs] 19839K-&gt;19595K(19840K), [Perm : 376K-&gt;376K(12288K)], 0.0302635 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0311986 secs] 19839K-&gt;19839K(19840K), [Perm : 376K-&gt;376K(12288K)], 0.0312515 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0358821 secs] 19839K-&gt;19825K(19840K), [Perm : 376K-&gt;371K(12288K)], 0.0359315 secs] [Times: user=0.05 sys=0.00, real=0.05 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0283080 secs] 19839K-&gt;19839K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0283723 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0284469 secs] 19839K-&gt;19839K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0284990 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0283005 secs] 19839K-&gt;19839K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0283475 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0287757 secs] 19839K-&gt;19839K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0288294 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0288219 secs] 19839K-&gt;19839K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0288709 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0293071 secs] 19839K-&gt;19839K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0293607 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 13695K-&gt;13695K(13696K), 0.0356141 secs] 19839K-&gt;19838K(19840K), [Perm : 371K-&gt;371K(12288K)], 0.0356654 secs] [Times: user=0.01 sys=0.00, real=0.03 secs] Heap def new generation total 6144K, used 6143K [0x35c10000, 0x362b0000, 0x362b0000) eden space 5504K, 100% used [0x35c10000, 0x36170000, 0x36170000) from space 640K, 99% used [0x36170000, 0x3620fc80, 0x36210000) to space 640K, 0% used [0x36210000, 0x36210000, 0x362b0000) tenured generation total 13696K, used 13695K [0x362b0000, 0x37010000, 0x37010000) the space 13696K, 99% used [0x362b0000, 0x3700fff8, 0x37010000, 0x37010000) compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706cd20, 0x3706ce00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 清单 2 所示的日志输出显示年轻代 Eden 的大小有 5MB 左右。分配足够大的年轻代空间，使用 JVM 参数-XX:+PrintGCDetails -Xmx20M -Xms20M-Xmn6M 运行清单 1 所示代码，输出如清单 3 所示。 清单 3. 增大 Eden 大小后清单 1 运行输出 [GC [DefNew: 4992K-&gt;576K(5568K), 0.0116036 secs] 4992K-&gt;4829K(19904K), 0.0116439 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] [GC [DefNew: 5568K-&gt;576K(5568K), 0.0130929 secs] 9821K-&gt;9653K(19904K), 0.0131336 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] [GC [DefNew: 5568K-&gt;575K(5568K), 0.0154148 secs] 14645K-&gt;14500K(19904K), 0.0154531 secs] [Times: user=0.00 sys=0.01, real=0.01 secs] [GC [DefNew: 5567K-&gt;5567K(5568K), 0.0000197 secs][Tenured: 13924K-&gt;14335K(14336K), 0.0330724 secs] 19492K-&gt;19265K(19904K), [Perm : 376K-&gt;376K(12288K)], 0.0331624 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 14335K-&gt;14335K(14336K), 0.0292459 secs] 19903K-&gt;19902K(19904K), [Perm : 376K-&gt;376K(12288K)], 0.0293000 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 14335K-&gt;14335K(14336K), 0.0278675 secs] 19903K-&gt;19903K(19904K), [Perm : 376K-&gt;376K(12288K)], 0.0279215 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured: 14335K-&gt;14335K(14336K), 0.0348408 secs] 19903K-&gt;19889K(19904K), [Perm : 376K-&gt;371K(12288K)], 0.0348945 secs] [Times: user=0.05 sys=0.00, real=0.05 secs] [Full GC [Tenured: 14335K-&gt;14335K(14336K), 0.0299813 secs] 19903K-&gt;19903K(19904K), [Perm : 371K-&gt;371K(12288K)], 0.0300349 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] [Full GC [Tenured: 14335K-&gt;14335K(14336K), 0.0298178 secs] 19903K-&gt;19903K(19904K), [Perm : 371K-&gt;371K(12288K)], 0.0298688 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space[Full GC [Tenured: 14335K-&gt;14335K(14336K), 0.0294953 secs] 19903K-&gt;19903K(19904K), [Perm : 371K-&gt;371K(12288K)], 0.0295474 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenured : 14335K-&gt;14335K(14336K), 0.0287742 secs] 19903K-&gt;19903K(19904K), [Perm : 371K-&gt;371K(12288K)], 0.0288239 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [Full GC [Tenuredat GCTimeTest.main(GCTimeTest.java:16) : 14335K-&gt;14335K(14336K), 0.0287102 secs] 19903K-&gt;19903K(19904K), [Perm : 371K-&gt;371K(12288K)], 0.0287627 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] Heap def new generation total 5568K, used 5567K [0x35c10000, 0x36210000, 0x36210000) eden space 4992K, 100% used [0x35c10000, 0x360f0000, 0x360f0000) from space 576K, 99% used [0x36180000, 0x3620ffe8, 0x36210000) to space 576K, 0% used [0x360f0000, 0x360f0000, 0x36180000) tenured generation total 14336K, used 14335K [0x36210000, 0x37010000, 0x37010000) the space 14336K, 99% used [0x36210000, 0x3700ffd8, 0x37010000, 0x37010000) compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706ce28, 0x3706d000, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 通过清单 2 和清单 3 对比，可以发现通过设置一个较大的年轻代预留新对象，设置合理的 Survivor 区并且提供 Survivor 区的使用率，可以将年轻对象保存在年轻代。一般来说，Survivor 区的空间不够，或者占用量达到 50%时，就会使对象进入年老代 (不管它的年龄有多大)。清单 4 创建了 3 个对象，分别分配一定的内存空间。 清单 4. 不同大小内存分配 public class PutInEden2 { public static void main(String[] args){ byte[] b1,b2,b3; b1=new byte[1024*512];//分配 0.5MB 堆空间 b2=new byte[1024*1024*4];//分配 4MB 堆空间 b3=new byte[1024*1024*4]; b3=null; //使 b3 可以被回收 b3=new byte[1024*1024*4];//分配 4MB 堆空间 } } 使用参数-XX:+PrintGCDetails -Xmx1000M -Xms500M -Xmn100M -XX:SurvivorRatio=8 运行清单 4 所示代码，输出如清单 5 所示。 清单 5. 清单 4 运行输出 Heap def new generation total 92160K, used 11878K [0x0f010000, 0x15410000, 0x15410000) eden space 81920K, 2% used [0x0f010000, 0x0f1a9a20, 0x14010000) from space 10240K, 99% used [0x14a10000, 0x1540fff8, 0x15410000) to space 10240K, 0% used [0x14010000, 0x14010000, 0x14a10000) tenured generation total 409600K, used 86434K [0x15410000, 0x2e410000, 0x4d810000) the space 409600K, 21% used [0x15410000, 0x1a878b18, 0x1a878c00, 0x2e410000) compacting perm gen total 12288K, used 2062K [0x4d810000, 0x4e410000, 0x51810000) the space 12288K, 16% used [0x4d810000, 0x4da13b18, 0x4da13c00, 0x4e410000) No shared spaces configured. 清单 5 输出的日志显示，年轻代分配了 8M，年老代也分配了 8M。我们可以尝试加上-XX:TargetSurvivorRatio=90 参数，这样可以提高 from 区的利用率，使 from 区使用到 90%时，再将对象送入年老代，运行清单 4 代码，输出如清单 6 所示。 清单 6. 修改运行参数后清单 4 输出 Heap def new generation total 9216K, used 9215K [0x35c10000, 0x36610000, 0x36610000) eden space 8192K, 100% used [0x35c10000, 0x36410000, 0x36410000) from space 1024K, 99% used [0x36510000, 0x3660fc50, 0x36610000) to space 1024K, 0% used [0x36410000, 0x36410000, 0x36510000) tenured generation total 10240K, used 10239K [0x36610000, 0x37010000, 0x37010000) the space 10240K, 99% used [0x36610000, 0x3700ff70, 0x37010000, 0x37010000) compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706cd90, 0x3706ce00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 如果将 SurvivorRatio 设置为 2，将 b1 对象预存在年轻代。输出如清单 7 所示。 清单 7. 再次修改运行参数后清单 4 输出 Heap def new generation total 7680K, used 7679K [0x35c10000, 0x36610000, 0x36610000) eden space 5120K, 100% used [0x35c10000, 0x36110000, 0x36110000) from space 2560K, 99% used [0x36110000, 0x3638fff0, 0x36390000) to space 2560K, 0% used [0x36390000, 0x36390000, 0x36610000) tenured generation total 10240K, used 10239K [0x36610000, 0x37010000, 0x37010000) the space 10240K, 99% used [0x36610000, 0x3700fff0, 0x37010000, 0x37010000) compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706ce28, 0x3706d000, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 如何让大对象进入年老代我们在大部分情况下都会选择将对象分配在年轻代。但是，对于占用内存较多的大对象而言，它的选择可能就不是这样的。因为大对象出现在年轻代很可能扰乱年轻代 GC，并破坏年轻代原有的对象结构。因为尝试在年轻代分配大对象，很可能导致空间不足，为了有足够的空间容纳大对象，JVM 不得不将年轻代中的年轻对象挪到年老代。因为大对象占用空间多，所以可能需要移动大量小的年轻对象进入年老代，这对 GC 相当不利。基于以上原因，可以将大对象直接分配到年老代，保持年轻代对象结构的完整性，这样可以提高 GC 的效率。如果一个大对象同时又是一个短命的对象，假设这种情况出现很频繁，那对于 GC 来说会是一场灾难。原本应该用于存放永久对象的年老代，被短命的对象塞满，这也意味着对堆空间进行了洗牌，扰乱了分代内存回收的基本思路。因此，在软件开发过程中，应该尽可能避免使用短命的大对象。可以使用参数-XX:PetenureSizeThreshold 设置大对象直接进入年老代的阈值。当对象的大小超过这个值时，将直接在年老代分配。参数-XX:PetenureSizeThreshold 只对串行收集器和年轻代并行收集器有效，并行回收收集器不识别这个参数。 清单 8. 创建一个大对象 public class BigObj2Old { public static void main(String[] args){ byte[] b; b = new byte[1024*1024];//分配一个 1MB 的对象 } } 使用 JVM 参数-XX:+PrintGCDetails –Xmx20M –Xms20MB 运行，可以得到清单 9 所示日志输出。 清单 9. 清单 8 运行输出 Heap def new generation total 6144K, used 1378K [0x35c10000, 0x362b0000, 0x362b0000) eden space 5504K, 25% used [0x35c10000, 0x35d689e8, 0x36170000) from space 640K, 0% used [0x36170000, 0x36170000, 0x36210000) to space 640K, 0% used [0x36210000, 0x36210000, 0x362b0000) tenured generation total 13696K, used 0K [0x362b0000, 0x37010000, 0x37010000) the space 13696K, 0% used [0x362b0000, 0x362b0000, 0x362b0200, 0x37010000) compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706dac8, 0x3706dc00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 可以看到该对象被分配在了年轻代，占用了 25%的空间。如果需要将 1MB 以上的对象直接在年老代分配，设置-XX:PetenureSizeThreshold=1000000，程序运行后输出如清单 10 所示。 清单 10. 修改运行参数后清单 8 输出 Heap def new generation total 6144K, used 354K [0x35c10000, 0x362b0000, 0x362b0000) eden space 5504K, 6% used [0x35c10000, 0x35c689d8, 0x36170000) from space 640K, 0% used [0x36170000, 0x36170000, 0x36210000) to space 640K, 0% used [0x36210000, 0x36210000, 0x362b0000) tenured generation total 13696K, used 1024K [0x362b0000, 0x37010000, 0x37010000) the space 13696K, 7% used [0x362b0000, 0x363b0010, 0x363b0200, 0x37010000) compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706dac8, 0x3706dc00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 清单 10 里面可以看到当满 1MB 时进入到了年老代。 如何设置对象进入年老代的年龄堆中的每一个对象都有自己的年龄。一般情况下，年轻对象存放在年轻代，年老对象存放在年老代。为了做到这点，虚拟机为每个对象都维护一个年龄。如果对象在 Eden 区，经过一次 GC 后依然存活，则被移动到 Survivor 区中，对象年龄加 1。以后，如果对象每经过一次 GC 依然存活，则年龄再加 1。当对象年龄达到阈值时，就移入年老代，成为老年对象。这个阈值的最大值可以通过参数-XX:MaxTenuringThreshold 来设置，默认值是 15。虽然-XX:MaxTenuringThreshold 的值可能是 15 或者更大，但这不意味着新对象非要达到这个年龄才能进入年老代。事实上，对象实际进入年老代的年龄是虚拟机在运行时根据内存使用情况动态计算的，这个参数指定的是阈值年龄的最大值。即，实际晋升年老代年龄等于动态计算所得的年龄与-XX:MaxTenuringThreshold 中较小的那个。清单 11 所示代码为 3 个对象申请了若干内存。 清单 11. 申请内存 public class MaxTenuringThreshold { public static void main(String args[]){ byte[] b1,b2,b3; b1 = new byte[1024*512]; b2 = new byte[1024*1024*2]; b3 = new byte[1024*1024*4]; b3 = null; b3 = new byte[1024*1024*4]; } } 参数设置为：-XX:+PrintGCDetails -Xmx20M -Xms20M -Xmn10M -XX:SurvivorRatio=2 运行清单 11 所示代码，输出如清单 12 所示。 清单 12. 清单 11 运行输出 [GC [DefNew: 2986K-&gt;690K(7680K), 0.0246816 secs] 2986K-&gt;2738K(17920K), 0.0247226 secs] [Times: user=0.00 sys=0.02, real=0.03 secs] [GC [DefNew: 4786K-&gt;690K(7680K), 0.0016073 secs] 6834K-&gt;2738K(17920K), 0.0016436 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 7680K, used 4888K [0x35c10000, 0x36610000, 0x36610000) eden space 5120K, 82% used [0x35c10000, 0x36029a18, 0x36110000) from space 2560K, 26% used [0x36110000, 0x361bc950, 0x36390000) to space 2560K, 0% used [0x36390000, 0x36390000, 0x36610000) tenured generation total 10240K, used 2048K [0x36610000, 0x37010000, 0x37010000) the space 10240K, 20% used [0x36610000, 0x36810010, 0x36810200, 0x37010000) compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706db50, 0x3706dc00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 更改参数为-XX:+PrintGCDetails -Xmx20M -Xms20M -Xmn10M -XX:SurvivorRatio=2 -XX:MaxTenuringThreshold=1，运行清单 11 所示代码，输出如清单 13 所示。 清单 13. 修改运行参数后清单 11 输出 [GC [DefNew: 2986K-&gt;690K(7680K), 0.0047778 secs] 2986K-&gt;2738K(17920K), 0.0048161 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC [DefNew: 4888K-&gt;0K(7680K), 0.0016271 secs] 6936K-&gt;2738K(17920K), 0.0016630 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 7680K, used 4198K [0x35c10000, 0x36610000, 0x36610000) eden space 5120K, 82% used [0x35c10000, 0x36029a18, 0x36110000) from space 2560K, 0% used [0x36110000, 0x36110088, 0x36390000) to space 2560K, 0% used [0x36390000, 0x36390000, 0x36610000) tenured generation total 10240K, used 2738K [0x36610000, 0x37010000, 0x37010000) the space 10240K, 26% used [0x36610000, 0x368bc890, 0x368bca00, 0x37010000) compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000) the space 12288K, 3% used [0x37010000, 0x3706db50, 0x3706dc00, 0x37c10000) ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000) rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000) 清单 13 所示，第一次运行时 b1 对象在程序结束后依然保存在年轻代。第二次运行前，我们减小了对象晋升年老代的年龄，设置为 1。即，所有经过一次 GC 的对象都可以直接进入年老代。程序运行后，可以发现 b1 对象已经被分配到年老代。如果希望对象尽可能长时间地停留在年轻代，可以设置一个较大的阈值。 稳定的 Java 堆 VS 动荡的 Java 堆一般来说，稳定的堆大小对垃圾回收是有利的。获得一个稳定的堆大小的方法是使-Xms 和-Xmx 的大小一致，即最大堆和最小堆 (初始堆) 一样。如果这样设置，系统在运行时堆大小理论上是恒定的，稳定的堆空间可以减少 GC 的次数。因此，很多服务端应用都会将最大堆和最小堆设置为相同的数值。但是，一个不稳定的堆并非毫无用处。稳定的堆大小虽然可以减少 GC 次数，但同时也增加了每次 GC 的时间。让堆大小在一个区间中震荡，在系统不需要使用大内存时，压缩堆空间，使 GC 应对一个较小的堆，可以加快单次 GC 的速度。基于这样的考虑，JVM 还提供了两个参数用于压缩和扩展堆空间。 -XX:MinHeapFreeRatio 参数用来设置堆空间最小空闲比例，默认值是 40。当堆空间的空闲内存小于这个数值时，JVM 便会扩展堆空间。 -XX:MaxHeapFreeRatio 参数用来设置堆空间最大空闲比例，默认值是 70。当堆空间的空闲内存大于这个数值时，便会压缩堆空间，得到一个较小的堆。 当-Xmx 和-Xms 相等时，-XX:MinHeapFreeRatio 和-XX:MaxHeapFreeRatio 两个参数无效。 清单 14. 堆大小设置 import java.util.Vector; public class HeapSize { public static void main(String args[]) throws InterruptedException{ Vector v = new Vector(); while(true){ byte[] b = new byte[1024*1024]; v.add(b); if(v.size() == 10){ v = new Vector(); } Thread.sleep(1); } } } 清单 14 所示代码是测试-XX:MinHeapFreeRatio 和-XX:MaxHeapFreeRatio 的作用，设置运行参数为-XX:+PrintGCDetails -Xms10M -Xmx40M -XX:MinHeapFreeRatio=40 -XX:MaxHeapFreeRatio=50 时，输出如清单 15 所示。 清单 15. 修改运行参数后清单 14 输出 [GC [DefNew: 2418K-&gt;178K(3072K), 0.0034827 secs] 2418K-&gt;2226K(9920K), 0.0035249 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] [GC [DefNew: 2312K-&gt;0K(3072K), 0.0028263 secs] 4360K-&gt;4274K(9920K), 0.0029905 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] [GC [DefNew: 2068K-&gt;0K(3072K), 0.0024363 secs] 6342K-&gt;6322K(9920K), 0.0024836 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] [GC [DefNew: 2061K-&gt;0K(3072K), 0.0017376 secs][Tenured: 8370K-&gt;8370K(8904K), 0.1392692 secs] 8384K-&gt;8370K(11976K), [Perm : 374K-&gt;374K(12288K)], 0.1411363 secs] [Times: user=0.00 sys=0.02, real=0.16 secs] [GC [DefNew: 5138K-&gt;0K(6336K), 0.0038237 secs] 13508K-&gt;13490K(20288K), 0.0038632 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] 改用参数：-XX:+PrintGCDetails -Xms40M -Xmx40M -XX:MinHeapFreeRatio=40 -XX:MaxHeapFreeRatio=50，运行输出如清单 16 所示。 清单 16. 再次修改运行参数后清单 14 输出 [GC [DefNew: 10678K-&gt;178K(12288K), 0.0019448 secs] 10678K-&gt;178K(39616K), 0.0019851 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] [GC [DefNew: 10751K-&gt;178K(12288K), 0.0010295 secs] 10751K-&gt;178K(39616K), 0.0010697 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] [GC [DefNew: 10493K-&gt;178K(12288K), 0.0008301 secs] 10493K-&gt;178K(39616K), 0.0008672 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] [GC [DefNew: 10467K-&gt;178K(12288K), 0.0008522 secs] 10467K-&gt;178K(39616K), 0.0008905 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] [GC [DefNew: 10450K-&gt;178K(12288K), 0.0008964 secs] 10450K-&gt;178K(39616K), 0.0009339 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC [DefNew: 10439K-&gt;178K(12288K), 0.0009876 secs] 10439K-&gt;178K(39616K), 0.0010279 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] 从清单 16 可以看出，此时堆空间的垃圾回收稳定在一个固定的范围。在一个稳定的堆中，堆空间大小始终不变，每次 GC 时，都要应对一个 40MB 的空间。因此，虽然 GC 次数减小了，但是单次 GC 速度不如一个震荡的堆。 增大吞吐量提升系统性能吞吐量优先的方案将会尽可能减少系统执行垃圾回收的总时间，故可以考虑关注系统吞吐量的并行回收收集器。在拥有高性能的计算机上，进行吞吐量优先优化，可以使用参数： java –Xmx3800m –Xms3800m –Xmn2G –Xss128k –XX:+UseParallelGC –XX:ParallelGC-Threads=20 –XX:+UseParallelOldGC –Xmx380m –Xms3800m：设置 Java 堆的最大值和初始值。一般情况下，为了避免堆内存的频繁震荡，导致系统性能下降，我们的做法是设置最大堆等于最小堆。假设这里把最小堆减少为最大堆的一半，即 1900m，那么 JVM 会尽可能在 1900MB 堆空间中运行，如果这样，发生 GC 的可能性就会比较高； -Xss128k：减少线程栈的大小，这样可以使剩余的系统内存支持更多的线程； -Xmn2g：设置年轻代区域大小为 2GB； –XX:+UseParallelGC：年轻代使用并行垃圾回收收集器。这是一个关注吞吐量的收集器，可以尽可能地减少 GC 时间。 –XX:ParallelGC-Threads：设置用于垃圾回收的线程数，通常情况下，可以设置和 CPU 数量相等。但在 CPU 数量比较多的情况下，设置相对较小的数值也是合理的； –XX:+UseParallelOldGC：设置年老代使用并行回收收集器。 尝试使用大的内存分页CPU 是通过寻址来访问内存的。32 位 CPU 的寻址宽度是 0~0xFFFFFFFF ，计算后得到的大小是 4G，也就是说可支持的物理内存最大是 4G。但在实践过程中，碰到了这样的问题，程序需要使用 4G 内存，而可用物理内存小于 4G，导致程序不得不降低内存占用。为了解决此类问题，现代 CPU 引入了 MMU（Memory Management Unit 内存管理单元）。MMU 的核心思想是利用虚拟地址替代物理地址，即 CPU 寻址时使用虚址，由 MMU 负责将虚址映射为物理地址。MMU 的引入，解决了对物理内存的限制，对程序来说，就像自己在使用 4G 内存一样。内存分页 (Paging) 是在使用 MMU 的基础上，提出的一种内存管理机制。它将虚拟地址和物理地址按固定大小（4K）分割成页 (page) 和页帧 (page frame)，并保证页与页帧的大小相同。这种机制，从数据结构上，保证了访问内存的高效，并使 OS 能支持非连续性的内存分配。在程序内存不够用时，还可以将不常用的物理内存页转移到其他存储设备上，比如磁盘，这就是大家耳熟能详的虚拟内存。 在 Solaris 系统中，JVM 可以支持 Large Page Size 的使用。使用大的内存分页可以增强 CPU 的内存寻址能力，从而提升系统的性能。 12java –Xmx2506m –Xms2506m –Xmn1536m –Xss128k –XX:++UseParallelGC –XX:ParallelGCThreads=20 –XX:+UseParallelOldGC –XX:+LargePageSizeInBytes=256m–XX:+LargePageSizeInBytes：设置大页的大小。 过大的内存分页会导致 JVM 在计算 Heap 内部分区（perm, new, old）内存占用比例时，会出现超出正常值的划分，最坏情况下某个区会多占用一个页的大小。 使用非占有的垃圾回收器为降低应用软件的垃圾回收时的停顿，首先考虑的是使用关注系统停顿的 CMS 回收器，其次，为了减少 Full GC 次数，应尽可能将对象预留在年轻代，因为年轻代 Minor GC 的成本远远小于年老代的 Full GC。 java –Xmx3550m –Xms3550m –Xmn2g –Xss128k –XX:ParallelGCThreads=20 –XX:+UseConcMarkSweepGC –XX:+UseParNewGC –XX:+SurvivorRatio=8 –XX:TargetSurvivorRatio=90 –XX:MaxTenuringThreshold=31 –XX:ParallelGCThreads=20：设置 20 个线程进行垃圾回收； –XX:+UseParNewGC：年轻代使用并行回收器； –XX:+UseConcMarkSweepGC：年老代使用 CMS 收集器降低停顿； –XX:+SurvivorRatio：设置 Eden 区和 Survivor 区的比例为 8:1。稍大的 Survivor 空间可以提高在年轻代回收生命周期较短的对象的可能性，如果 Survivor 不够大，一些短命的对象可能直接进入年老代，这对系统来说是不利的。 –XX:TargetSurvivorRatio=90：设置 Survivor 区的可使用率。这里设置为 90%，则允许 90%的 Survivor 空间被使用。默认值是 50%。故该设置提高了 Survivor 区的使用率。当存放的对象超过这个百分比，则对象会向年老代压缩。因此，这个选项更有助于将对象留在年轻代。 –XX:MaxTenuringThreshold：设置年轻对象晋升到年老代的年龄。默认值是 15 次，即对象经过 15 次 Minor GC 依然存活，则进入年老代。这里设置为 31，目的是让对象尽可能地保存在年轻代区域。 结束语通过本文的学习，读者了解了如何将新对象预留在年轻代、如何让大对象进入年老代、如何设置对象进入年老代的年龄、稳定的 Java 堆 VS 动荡的 Java 堆、增大吞吐量提升系统性能、尝试使用大的内存分页、使用非占有的垃圾回收器等主题，通过实例及对应输出解释的形式让读者对于 JVM 优化有一个初步认识。如其他文章相同的观点，没有哪一条优化是固定不变的，读者需要自己判断、实践后才能找到正确的道路。","path":"/2018/4/3/","date":"04-03","preview":"https://wx3.sinaimg.cn/large/00632Q2nly1fw8py7fzduj30yg0p3e29.jpg","subtitle":"我慢慢去想奶奶讲的那个神话，我慢慢相信，每一个活过的人，都能给后人的路途上添些光亮，也许是一颗巨星，也许是一把火炬，也许只是一支含泪的蜡烛。"},{"title":"java编码规范","text":"采用 4 个空格缩进，禁止使用 tab 字符。 if/for/while/switch/do 等保留字与括号之间都必须加空格。 大括号的使用约定。如果是大括号内为空，则简洁地写成{}即可，不需要换行;如果 是非空代码块则: 1) 左大括号前不换行。 2) 左大括号后换行。 3) 右大括号前换行。 4) 右大括号后还有else等代码则不换行;表示终止的右大括号后必须换行。 public static void main(String[] args) { // 缩进 4 个空格 String say = &quot;hello&quot;; // 运算符的左右必须有一个空格 int flag = 0; // 关键词 if 与括号之间必须有一个空格，括号内的 f 与左括号，0 与右括号不需要空格 if (flag == 0) { System.out.println(say); } // 左大括号前加空格且不换行;左大括号后换行 if (flag == 1) { System.out.println(&quot;world&quot;); // 右大括号前换行，右大括号后有 else，不用换行 } else { System.out.println(&quot;ok&quot;); // 在右大括号后直接结束，则必须换行 } } 注释的双斜线与注释内容之间有且仅有一个空格。 方法参数在定义和传入时，多个参数逗号后边必须加空格。 method(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); 不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。 定义 DO/DTO/VO 等 POJO 类时，不要设定任何属性默认值。 构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在 init 方法中。 类内方法定义的顺序依次是:公有方法或保护方法 &gt; 私有方法 &gt; getter/setter方法。 不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator方式，如果并发操作，需要对 Iterator 对象加锁。Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext()) { String item = iterator.next(); if (删除元素的条件) { iterator.remove(); } } 使用 entrySet 遍历 Map 类集合 KV，而不是 keySet 方式进行遍历。说明:keySet 其实是遍历了 2 次，一次是转为 Iterator 对象，另一次是从 hashMap 中取出 key 所对应的 value。而 entrySet 只是遍历了一次就把 key 和 value 都放到了 entry 中，效 率更高。如果是 JDK8，使用 Map.foreach 方法。 多线程并行处理定时任务时，Timer 运行多个 TimeTask 时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。 在高并发场景中，避免使用”等于”判断作为中断或退出的条件。 说明:如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间 判断条件来代替。 很多 if 语句内的逻辑相当复杂，阅读者需要分析条件表达式的最终结果，才能明确什么 样的条件执行什么样的语句，那么，如果阅读者分析逻辑表达式错误呢? 正例: final boolean existed = (file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...); if (existed) {... } 反例: if ((file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...)) { ...} 谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。 对 trace/debug/info级别的日志输出，必须使用条件输出形式或者使用占位符的方 式。 if (logger.isDebugEnabled()) { //条件 logger.debug(&quot;Processing trade with id: {} and symbol : {} &quot;, id, symbol); //占位符 } 后台输送给页面的变量必须加$!{var}——中间的感叹号。 任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。 对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三 个斜杠(///)来说明注释掉代码的理由。 单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元 测试中不准使用 System.out 来进行人肉验证，必须使用 assert 来验证。 用户请求传入的任何参数必须做有效性验证。 禁止向 HTML页面输出未经安全过滤或未正确转义的用户数据。 库名与应用名称尽量一致。 MySQL数据库 表必备三字段:id, gmt_create, gmt_modified。 说明:其中id必为主键，类型为unsigned bigint、单表时自增、步长为1。gmt_create, gmt_modified 的类型均为 datetime 类型，前者现在时表示主动创建，后者过去分词表示被 动更新。 表的命名最好是加上“业务名称_表的作用”。 正例:alipay_task / force_project / trade_config 超过三个表禁止 join。需要 join 的字段，数据类型必须绝对一致;多表关联查询时， 保证被关联的字段需要有索引。 建组合索引的时候，区分度最高的在最左边。存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。 不要使用 count(列名)或 count(常量)来替代 count()，count()是 SQL92 定义的 标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。 说明:count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。 当某一列的值全是 NULL 时，count(col)的返回结果为 0，但 sum(col)的返回结果为 NULL，因此使用 sum()时需注意 NPE 问题。 正例:可以使用如下方式来避免sum的NPE问题: SELECT IF(ISNULL(SUM(g)),0,SUM(g)) FROM table; 在代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句。 禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控 制在 1000 个之内。 POJO 类的布尔属性不能加 is，而数据库字段必须加 is_，要求在 resultMap 中进行 字段与属性之间的映射。 不要写一个大而全的数据更新接口。传入为 POJO 类，不管是不是自己的目标更新字段，都进行 update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行 SQL 时，不要更新无改动的字段，一是易出错;二是效率低;三是增加 binlog 存储。 @Transactional 事务不要滥用。事务会影响数据库的 QPS，另外使用事务的地方需 要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。","path":"/2018/4/2/","date":"04-02","preview":"https://isux.tencent.com/static/images/resources/banner-2.jpg","subtitle":"查看阿里的  《java开发手册》复制出来的  前人总结的经验   为了 告诫自己"},{"title":"项目配置运行","text":"bugbug 1: 三月 14, 2018 9:39:36 下午 org.apache.catalina.core.StandardContext loadOnStartup 严重: Servlet [ApiInitializer] in web application [] threw load() exception org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type &#39;com.technow.bbclip.common.logic.component.SiteComponent&#39; available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)} at org.springframework.beans.factory.support.DefaultListableBeanFactory.raiseNoMatchingBeanFound(DefaultListableBeanFactory.java:1493) at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1104) at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:585) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1264) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) **报错原因**：由于没有加载成功spring容器，导致注入时没有重spring容器中找到被注入对象。 **寻找问题**：查看spring配置发现 @Profile 注解，只有激活此注解才会执行 **解决方法**: ``作为JVM的系统属性,传入-Dspring.profiles.active=值，激活带有@Profile（值)`` 环境与Profile 1. 原因： 在开发阶段，某些环境相关的配置并不适合直接迁移到生产环境中。比如数据库配置、加密算法以及与外部系统的集成是跨环境部署。 2. Spring提供的解决方案 在3.1版本中，spring引入了bean profile功能。通过将可能发生变化的不同的bean定义到一个或多个profile中，当其对应的profile处于激活(active)状态时，则该bean生效。 初始化指令处理组件时，注入所有指令，spring在什么时候将所有指令加入到容器中的呢？原因：因为在spring执行到扫描包的时候，spring将所有带有spring注解的Bean，都注入到spring容器中，所以在初始化指令处理组件时可以将所有指令注入","path":"/2018/3/26/","date":"03-26","preview":"https://upload-images.jianshu.io/upload_images/12906348-64e774f43def3c1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"VM options： -Dspring.profiles.active=personal_dev传给spring加载指定：类注解@Profile(\"personal_dev\")  的类"},{"title":"Apache Thrift - 可伸缩的跨语言服务开发框架","text":"目前流行的服务调用方式有很多种，例如基于 SOAP 消息格式的 Web Service，基于 JSON 消息格式的 RESTful 服务等。其中所用到的数据传输方式包括 XML，JSON 等，然而 XML 相对体积太大，传输效率低，JSON 体积较小，新颖，但还不够完善。本文将介绍由 Facebook 开发的远程服务调用框架 Apache Thrift……Apache Thrift它采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，对于高并发、大数据量和多语言的环境更有优势。本文将详细介绍 Thrift 的使用，并且提供丰富的实例代码加以解释说明，帮助使用者快速构建服务。` IBM教程 https://www.ibm.com/developerworks/cn/java/j-lo-apachethrift/","path":"/2018/3/23/","date":"03-23","preview":"https://images.pexels.com/photos/929032/pexels-photo-929032.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"目前流行的服务调用方式有很多种，例如基于 SOAP 消息格式的 Web Service，基于 JSON 消息格式的 RESTful 服务等。其中所用到的数据传输方式包括 XML，JSON 等，然而 XML 相对体积太大，传输效率低，JSON 体积较小，新颖，但还不够完善。本文将介绍由 Facebook 开发的远程服务调用框架 Apache Thrift..."},{"title":"spring","text":"spring （由Rod Johnson创建的一个开源框架） 编辑Spring是一个开放源代码的设计层面框架，他解决的是业务逻辑层和其他各层的松耦合问题，因此它将面向接口的编程思想贯穿整个系统应用。Spring是于2003 年兴起的一个轻量级的Java 开发框架，由Rod Johnson创建。简单来说，Spring是一个分层的JavaSE/EE full-stack(一站式) 轻量级开源框架。Spring致力于J2EE应用的各层的解决方案，而不是仅仅专注于某一层的方案。可以说Spring是企业应用开发的“一站式”选择，并贯穿表现层、业务层及持久层。然而，Spring并不想取代那些已有的框架，而是与它们无缝地整合。 框架特征编辑 1.轻量——从大小与开销两方面而言Spring都是轻量的。完整的Spring框架可以在一个大小只有1MB多的JAR文件里发布。并且Spring所需的处理开销也是微不足道的。此外，Spring是非侵入式的：典型地，Spring应用中的对象不依赖于Spring的特定类。 2.控制反转——Spring通过一种称作控制反转（IoC）的技术促进了低耦合。当应用了IoC，一个对象依赖的其它对象会通过被动的方式传递进来，而不是这个对象自己创建或者查找依赖对象。你可以认为IoC与JNDI相反——不是对象从容器中查找依赖，而是容器在对象初始化时不等对象请求就主动将依赖传递给它。 3.面向切面——Spring提供了面向切面编程的丰富支持，允许通过分离应用的业务逻辑与系统级服务（例如审计（auditing）和事务（transaction）管理）进行内聚性的开发。应用对象只实现它们应该做的——完成业务逻辑——仅此而已。它们并不负责（甚至是意识）其它的系统级关注点，例如日志或事务支持。 4.容器——Spring包含并管理应用对象的配置和生命周期，在这个意义上它是一种容器，你可以配置你的每个bean如何被创建——基于一个可配置原型（prototype），你的bean可以创建一个单独的实例或者每次需要时都生成一个新的实例——以及它们是如何相互关联的。然而，Spring不应该被混同于传统的重量级的EJB容器，它们经常是庞大与笨重的，难以使用。 5.框架——Spring可以将简单的组件配置、组合成为复杂的应用。在Spring中，应用对象被声明式地组合，典型地是在一个XML文件里。Spring也提供了很多基础功能（事务管理、持久化框架集成等等），将应用逻辑的开发留给了你。 6.MVC——Spring的作用是整合，但不仅仅限于整合，Spring 框架可以被看做是一个企业解决方案级别的框架。客户端发送请求，服务器控制器（由DispatcherServlet实现的)完成请求的转发，控制器调用一个用于映射的类HandlerMapping，该类用于将请求映射到对应的处理器来处理请求。HandlerMapping 将请求映射到对应的处理器Controller（相当于Action）在Spring 当中如果写一些处理器组件，一般实现Controller 接口，在Controller 中就可以调用一些Service 或DAO 来进行数据操作 ModelAndView 用于存放从DAO 中取出的数据，还可以存放响应视图的一些数据。 如果想将处理结果返回给用户，那么在Spring 框架中还提供一个视图组件ViewResolver，该组件根据Controller 返回的标示，找到对应的视图，将响应response 返回给用户。 7.所有Spring的这些特征使你能够编写更干净、更可管理、并且更易于测试的代码。它们也为Spring中的各种模块提供了基础支持。","path":"/2018/3/22/","date":"03-22","preview":"https://images.pexels.com/photos/434555/pexels-photo-434555.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"A gecko can support its entire body weight with one toe. 壁虎能挂住整个身体,只用一个脚趾头。TED演讲（音频版） 2015年6月合集"},{"title":"mysqlBatch","text":"insert into tableName(type1,type2,type3) values (“q1”,”w1”,”e1”),( “q2”,”w2”,”e2”) ,( “q3”,”w3”,”e3”)；&nbsp;UPDATE app_history_statistics_by_hour SET h00 = CASE statisticalType WHEN “qqq” THEN 11111 WHEN “www” THEN 22211 WHEN ‘eee’ THEN 333111 ELSE 0 END WHERE weeks=’222’;由于表结构有限，所以没能用实体一一对应，所以只能用hqlhibernate &nbsp;hql &nbsp;批量插入 没找到固有的方法，所以 用以上方法，速度提升很多","path":"/2018/3/20/","date":"03-20","preview":"https://sandbox.runjs.cn/uploads/rs/247/l96nyyh9/mysql-logo.svg","subtitle":"mysql 批量value插入 批量update case when then"},{"title":"Mybatis与Hibernate","text":"Mybatis与Hibernate mybatis官网 github地址 hibernate是全自动，而mybatis是半自动hibernate完全可以通过对象关系模型实现对数据库的操作，拥有完整的JavaBean对象与数据库的映射结构来自动生成sql。而mybatis仅有基本的字段映射，对象数据以及对象实际关系仍然需要通过手写sql来实现和管理。 hibernate数据库移植性远大于mybatishibernate通过它强大的映射结构和hql语言，大大降低了对象与数据库(oracle、mysql等)的耦合性，而mybatis由于需要手写sql，因此与数据库的耦合性直接取决于程序员写sql的方法，如果sql不具通用性而用了很多某数据库特性的sql语句的话，移植性也会随之降低很多，成本很高。 hibernate拥有完整的日志系统，mybatis则欠缺一些hibernate日志系统非常健全，涉及广泛，包括：sql记录、关系异常、优化警告、缓存提示、脏数据警告等;而mybatis则除了基本记录功能外，功能薄弱很多。 mybatis相比hibernate需要关心很多细节hibernate配置要比mybatis复杂的多，学习成本也比mybatis高。但也正因为mybatis使用简单，才导致它要比hibernate关心很多技术细节。mybatis由于不用考虑很多细节，开发模式上与传统jdbc区别很小，因此很容易上手并开发项目，但忽略细节会导致项目前期bug较多，因而开发出相对稳定的软件很慢，而开发出软件却很快。hibernate则正好与之相反。但是如果使用hibernate很熟练的话，实际上开发效率丝毫不差于甚至超越mybatis。 sql直接优化上，mybatis要比hibernate方便很多由于mybatis的sql都是写在xml里，因此优化sql比hibernate方便很多。而hibernate的sql很多都是自动生成的，无法直接维护sql;虽有hql，但功能还是不及sql强大，见到报表等变态需求时，hql也歇菜，也就是说hql是有局限的;hibernate虽然也支持原生sql，但开发模式上却与orm不同，需要转换思维，因此使用上不是非常方便。总之写sql的灵活度上hibernate不及mybatis。随着使用情况的不断增多，我又做了进一步的总结总结： mybatis：小巧、方便、高效、简单、直接、半自动 hibernate：强大、方便、高效、复杂、绕弯子、全自动 mybatis： 入门简单，即学即用，提供了数据库查询的自动对象绑定功能，而且延续了很好的SQL使用经验，对于没有那么高的对象模型要求的项目来说，相当完美。 可以进行更为细致的SQL优化，可以减少查询字段。 缺点就是框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。 二级缓存机制不佳。 hibernate： 功能强大，数据库无关性好，O/R映射能力强，如果你对Hibernate相当精通，而且对Hibernate进行了适当的封装，那么你的项目整个持久层代码会相当简单，需要写的代码很少，开发速度很快，非常爽。 有更好的二级缓存机制，可以使用第三方缓存。 缺点就是学习门槛不低，要精通门槛更高，而且怎么设计O/R映射，在性能和对象模型之间如何权衡取得平衡，以及怎样用好Hibernate方面需要你的经验和能力都很强才行。 举个形象的比喻： mybatis：机械工具，使用方便，拿来就用，但工作还是要自己来作，不过工具是活的，怎么使由我决定。 hibernate：智能机器人，但研发它(学习、熟练度)的成本很高，工作都可以摆脱他了，但仅限于它能做的事。","path":"/2018/3/19/","date":"03-19","preview":"https://upload-images.jianshu.io/upload_images/12906348-3e6b62e5b503ca3c?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"生命力的意义在于拚搏，因为世界本身就是一个竞技场，就是无数次被礁石击碎又无数闪地扑向礁石，生命的绿荫才会越长越茂盛。"},{"title":"Linux输命令","text":"Linux同步命令(断点断续):rsync -P Documents/IWorkSpace/SendMail/out/artifacts/SendMail_jar/SendMail.jar testRetailer:~ 连接国外网络不好，使用rsync代替scp命令远程传输大文件 最近到国外的网络环境很差，丢包率大的感人，还时不时地断开，这时候如果要在本机和远程服务器间使用scp命令传输大文件的话，成功与否只能看运气了。传输过程中一个不小心断开了，只好从头再来一遍。其实对于大文件的传输，我们可以使用rsync来代替scp命令。 连接国外网络不好，使用rsync代替scp命令远程传输大文件 rsync主要是在类unix系统下作为数据镜像备份和文件同步工具使用的，从软件的命名上就可以看出来了——remote sync。 它的特性如下： 可以镜像保存整个目录树和文件系统。可以很容易做到保持原来文件的权限、时间、软硬链接等等。无须特殊权限即可安装。优化的流程，文件传输效率高。可以使用rcp、ssh等方式来传输文件，当然也可以通过直接的socket连接。支持匿名传输。这里我们只用它能够断点续传的特点在网络不好的环境下传输大的文件，算是有点大材小用了。就传输单个文件来说，它的用法和scp命令差不多，比如我要把远程服务器linode-server上的数据库备份文件database-backup.sql保存到本地。 命令形式如下： xxx@xxx:~$ rsync -P user@ip:/home/daweibro/database-backup.sql /home/daweibro/. daweobro@linode-server’s password:database-backup.sql 34,948,241 100% 96.58kB/s 0:05:53 (xfr#1, to-chk=0/1)rsync默认使用ssh的22端口，那么如果我们的服务器为了安全已经修改成其他的端口，比如端口是1234那怎么办呢？可以加上 -e ‘ssh -p 1234’参数来指定端口号： rsync -P -e &#39;ssh -p 1234&#39; user@ip:/home/daweibro/database-backup.sql /home/daweibro/.","path":"/2018/3/13/","date":"03-13","preview":"https://images.pexels.com/photos/119404/pexels-photo-119404.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"rsync代替scp命令远程传输大文件，支持断点断续"},{"title":"shell 脚本中 执行mysql查询语句并将结果导出excel中，表内容与表头别名中文乱码问题","text":"解决表内容乱码在执行mysql查询语句前指定编码==–default-character-set gbk== mysql -N -hlocalhost -uroot -p123456 --default-character-set gbk tms_ems_test2 -e &quot;select cchannelName from channel;&quot;&gt; channel.xls #-N去掉表头 按列展示 解决在shell脚本中执行sql语句表头别名乱码问题mysql -hlocalhost -uroot -p123456 tms_ems_test2 -e &quot;select cchannelName as &#39;频道名称&#39; from channel;&quot;&gt; channel.xls iconv -f utf8 -t gbk channel.xls -o channel.xls #将utf8转为gbk","path":"/2018/3/8/","date":"03-08","preview":"https://upload-images.jianshu.io/upload_images/12906348-3402bce557fedf13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"mysql 导出select语句结果到excel文件，中文乱码问题，语句中将表头重新命名为中文导出到excel乱码"},{"title":"java开发","text":"我要向风一样带走蒲公英，谢谢，大家让一让","path":"/2018/3/7/","date":"03-07","preview":"https://upload-images.jianshu.io/upload_images/12906348-ff2861df94c193d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","subtitle":"这个世界上，无解的事很多，比如说，如果你可以早一分钟，或者只要早几秒钟，你是不是就会和某个人，某件事产生连接。但往往大部分的人生我们总是在错过。"},{"title":"SpringMVC与struts2的区别","text":"然后简单说一下Spring MVC与Spring的关系。Spring可以说是一个管理bean的容器，也可以说是包括很多开源项目的总称，而Spring MVC是其中一个开源项目。如果简单进行一个流程，当http请求一到，由容器（如：Tomcat）解析http形成一个request，通过映射关系（比如路径，方法，参数）被Spring MVC一个分发器去找到可以处理这个请求的bean，在Tomcat里面就由Spring管理bean的一个池子（bean容器）里面找到。处理完了就把响应返回。 Struts2是类级别的拦截， 一个类对应一个request上下文，SpringMVC是方法级别的拦截，一个方法对应一个request上下文，而方法同时又跟一个url对应,所以说从架构本身上SpringMVC就容易实现restful url,而struts2的架构实现起来要费劲，因为Struts2中Action的一个方法可以对应一个url，而其类属性却被所有方法共享，这也就无法用注解或其他方式标识其所属方法了。 由上边原因，SpringMVC的方法之间基本上独立的，独享request response数据，请求数据通过参数获取，处理结果通过ModelMap交回给框架，方法之间不共享变量，而Struts2搞的就比较乱，虽然方法之间也是独立的，但其所有Action变量是共享的，这不会影响程序运行，却给我们编码 读程序时带来麻烦，每次来了请求就创建一个Action，一个Action对象对应一个request上下文。 由于Struts2需要针对每个request进行封装，把request，session等servlet生命周期的变量封装成一个一个Map，供给每个Action使用，并保证线程安全，所以在原则上，是比较耗费内存的。 拦截器实现机制上，Struts2有以自己的interceptor机制，SpringMVC用的是独立的AOP方式，这样导致Struts2的配置文件量还是比SpringMVC大。 SpringMVC的入口是servlet，而Struts2是filter（这里要指出，filter和servlet是不同的。以前认为filter是servlet的一种特殊），这就导致了二者的机制不同，这里就牵涉到servlet和filter的区别了。 SpringMVC集成了Ajax，使用非常方便，只需一个注解@ResponseBody就可以实现，然后直接返回响应文本即可，而Struts2拦截器集成了Ajax，在Action中处理时一般必须安装插件或者自己写代码集成进去，使用起来也相对不方便。 SpringMVC验证支持JSR303，处理起来相对更加灵活方便，而Struts2验证比较繁琐，感觉太烦乱。 Spring MVC和Spring是无缝的。从这个项目的管理和安全上也比Struts2高（当然Struts2也可以通过不同的目录结构和相关配置做到SpringMVC一样的效果，但是需要xml配置的地方不少）。 设计思想上，Struts2更加符合OOP的编程思想， SpringMVC就比较谨慎，在servlet上扩展。 SpringMVC开发效率和性能高于Struts2。 SpringMVC可以认为已经100%零配置。 Spring MVC 执行流程 Spring MVC 执行流程如下，共包括八步： Spring MVC 相关接口解释： 1）DispatcherServlet 前端控制器，所有的请求都有经过它来统一分发，请求会被分发给对应的 Handler。 2）HandlerMapping（处理器映射器） 解析请求链接，然后根据请求链接找到执行这个请求的类（HandlerMapping 所说的 handler）。 3）HandlerAdapter（处理器适配器） 调用具体的方法对用户发来的请求来进行处理。 4）Controller Controller 将处理用户请求，Controller 处理完用户请求，则返回 ModelAndView 对象给 DispatcherServlet 前端控制器。 从宏观角度考虑，DispatcherServlet 是整个 Web 应用的控制器；从微观考虑，Controller 是单个 Http 请求处理过程中的控制器。 5）ViewResolver（视图解析器） 解析 MdoelAndView，将 MdoelAndView 中的逻辑视图名变为一个真正的 View 对象，并将 MdoelAndView 中的 Model 取出。","path":"/2018/3/5/","date":"03-05","preview":"https://images.pexels.com/photos/365341/pexels-photo-365341.jpeg?auto=compress&cs=tinysrgb&h=453&w=680","subtitle":"You can talk to that author you love, ask him anything you want."},{"title":"Hibernate中get和load方法的区别","text":"对于get方法，hibernate会确认一下该id对应的数据是否存在，首先在session缓存中查找，然后在二级缓存中查找，还没有就查询数据库，数据库中没有就返回null。这个相对比较简单，也没有太大的争议。主要要说明的一点就是在这个版本中get方法也会查找二级缓存！ load方法加载实体对象的时候，根据映射文件上类级别的lazy属性的配置(默认为true)，分情况讨论：(1)若为true,则首先在Session缓存中查找，看看该id对应的对象是否存在，不存在则使用延迟加载，返回实体的代理类对象(该代理类为实体类的子类，由CGLIB动态生成)。等到具体使用该对象(除获取OID以外)的时候，再查询二级缓存和数据库，若仍没发现符合条件的记录，则会抛出一个ObjectNotFoundException。(2)若为false,就跟get方法查找顺序一样，只是最终若没发现符合条件的记录，则会抛出一个ObjectNotFoundException。 这里get和load有两个重要区别: 如果未能发现符合条件的记录，get方法返回null，而load方法会抛出一个ObjectNotFoundException。 load方法可返回没有加载实体数据的代理类实例，而get方法永远返回有实体数据的对象。(对于load和get方法返回类型：好多书中都说：“get方法永远只返回实体类”，实际上并不正确，get方法如果在session缓存中找到了该id对应的对象，如果刚好该对象前面是被代理过的，如被load方法使用过，或者被其他关联对象延迟加载过，那么返回的还是原先的代理对象，而不是实体类对象，如果该代理对象还没有加载实体数据（就是id以外的其他属性数据），那么它会查询二级缓存或者数据库来加载数据，但是返回的还是代理对象，只不过已经加载了实体数据。) 总之对于get和load的根本区别，一句话 hibernate对于load方法认为该数据在数据库中一定存在，可以放心的使用代理来延迟加载，如果在使用过程中发现了问题，只能抛异常；而对于get方法，hibernate一定要获取到真实的数据，否则返回null。","path":"/2018/3/3/","date":"03-03","preview":"https://sandbox.runjs.cn/uploads/rs/247/l96nyyh9/hibernate-logo.svg","subtitle":"Hibernate中get和load方法的区别"},{"title":"Find命令是Linux文件查找利器吗?","text":"再来谈一谈怎么查找文件。在Linux下面也有相当优异的查找命令。通常find不很常用的，因为速度慢！通常我们都是先使用whereis或者是locate来检查，如果真的找不到了，才以find来查找。为什么呢？因为whereis与locate是利用数据库来查找数据，所以相当快速，而且并没有实际查询硬盘，比较节省时间。引用来自: 鸟哥. “鸟哥的Linux私房菜 基础学习篇(第三版)。” Apple Books. find语法find [PATH] [option] [action] 参数:😁与时间有关的参数：共有 –atime、-ctime 与 -mtime,下面以 -mtime 说明: -mtime n ：n 为数字，意义为在 n 天之前的“一天之内”被更改过的文件； -mtime +n ：列出在 n 天之前（不含 n 天本身）被更改过的文件名； -mtime -n ：列出在 n 天之内（含 n 天本身）被更改过的文件名； -newer file ：file 为一个存在的文件，列出比 file 还要新的文件名。 范例：1. 将过去系统上面 24 小时内有改动（mtime）的文件列出find / -mtime 0 那个 0 是重点！0 代表目前的时间，所以，从现在开始到 24 小时前，有改动过内容的文件都会被列出来！2. 3天前的 24 小时内有改动（mtime）的文件列出find / -mtime 3 3. 寻找 /etc 下面的文件，如果文件日期比 /etc/passwd 新就列出find /etc -newer /etc/passwd -newer 用在分辨两个文件之间的新旧关系是很有用的！4. 找出“4天内被改动过的文件名”呢？find /var -mtime -4 5. 那如果是“4 天前的那一天”呢？find/var -mtime 4 有没有加上“+, -”差别很大。 +4 代表大于等于5 天前的文件名：find /var -mtime +4 – -4 代表小于等于4 天内的文件名：find /var -mtime -4 — 4 则是代表4～5 那一天的文件名： find /var -mtime 4 🤠与用户或用户组名有关的参数： -uid n ：n 为数字，这个数字是用户的账号 ID，即 UID，这个 UID 是记录在/etc/passwd 里面与账号名称对应的数字。 -gid n ：n 为数字，这个数字是用户组名的 ID，即 GID，这个 GID 记录在/etc/group中～ -user name ：name 为用户账号名称。例如 dmtsai。 -group name：name 为用户组名，例如 users。 -nouser ：寻找文件的所有者不存在 /etc/passwd 的人。 -nogroup ：寻找文件的所有用户组不存在于 /etc/group中的文件。当你自行安装软件时，很可能该软件的属性当中并没有文件所有者，这是可能的，在这个时候，就可以使用 -nouser 与 -nogroup 查找。范例：1. 查找 /home 目录下 属于 vbird 的文件find /home -user vbird 2. 查找 /home 目录下 系统中不属于任何人的文件find /home -nouser 🤪与文件权限昵称有关的参数： -name filename：查找文件名为 filename 的文件。 -size [+-]SIZE：查找比 SIZE 还要大（+）或小（-）的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB还要大的文件，就是“ -size +50k ”。 -type TYPE ：查找文件的类型为 TYPE 的，类型主要有：一般正规文件（f）、设备文件（b, c）、目录（d）、连接文件（l）、socket（s）、及 FIFO（p） 等属性。 -perm mode ：查找文件权限“刚好等于”mode 的文件，这个 mode 为类似 chmod的属性值，举例来说，-rwsr-xr-x 的属性为 4755 。 -perm -mode ：查找文件权限“必须要全部包括 mode 的权限”的文件，举例来说，我们要查找 -rwxr–r–，即 0744 的文件，使用 -perm -0744，当一个文件的权限为 -rwsr-xr-x，即 4755 […]范例：1. 查找 /home 目录下 文件名为 government.txtfind /home -name government.txt 2. 找出 /var 目录下文件类型为 Socket 的文件名有哪些find /var -type s 3. 要找出那些怪异的文件，例如 socket 与 FIFO 文件，可以用find /var -type p # 或 -type s 来找！ 4. 查找文件当中含有 SGID 或 SUID 或 SBIT 的属性find / -perm +7000 所谓的 7000 就是 —s–s–t，那么只要含有 s 或 t 的就列出，所以当然要使用 +7000，使用 -7000 表示要含有 —s–s–t 的所有三个权限，因此，就是 +7000 。5. find 支持通配符，查找文件名包含.log的文件find / -name &quot;*.log*&quot;","path":"/2017/10/19/","date":"10-19","preview":"https://images.pexels.com/photos/159740/library-la-trobe-study-students-159740.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=453&w=680","subtitle":"想不想找最近修改过的文件?<br/>想不想找<span style='color: #ff0000;font-size:25px;'>一个月 · 前·</span>修改过的文件?<br/><span style='color: #f9690e;'>so easy</span>!"}]